{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4QK61p/lLCZqOdjtuZNB+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/y123ash/AI7/blob/main/UntitledX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F46KmupH9M4",
        "outputId": "efe821f3-c065-4389-967f-bc882713e119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update the path below to where the Agent-E zip is in your Drive\n",
        "!unzip -q \"/content/drive/MyDrive/Agent-E-master_xxx (3).zip\" -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUmO0fFaI6GI",
        "outputId": "a37d8a27-c475-4c8b-9e87-c43107e9c6bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/Agent-E-master_xxx/.check-env-example? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/Agent-E-master_xxx /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "G3gwhdYzxJNz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the print and return bugs in openai_llm_helper.py\n",
        "!sed -i 's/print response/print(response)/g' /content/Agent-E-master_xxx (3).zip/ae/utils/openai_llm_helper.py\n",
        "!sed -i 's/return  Response/return response/g' /content/Agent-E-master_xxx (3).zip/ae/utils/openai_llm_helper.py"
      ],
      "metadata": {
        "id": "e8sjPyIWJbJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c9e660-a479-43b0-b86f-598687ec0533"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `sed -i 's/print response/print(response)/g' /content/Agent-E-master_xxx (3).zip/ae/utils/openai_llm_helper.py'\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `sed -i 's/return  Response/return response/g' /content/Agent-E-master_xxx (3).zip/ae/utils/openai_llm_helper.py'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfq5zPfvfZBg",
        "outputId": "f6302025-4a40-424d-b42d-8f820818be0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent-E-master_xxx  drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Python libraries\n",
        "!pip install -r /content/Agent-E-master_xxx/requirements.txt\n",
        "\n",
        "# Install the Agent-E project as a package\n",
        "%pip install -e /content/Agent-E-master_xxx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe5AUOmjfzwT",
        "outputId": "2ee95815-1d42-40bf-d9bf-38e47422b760"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 3)) (0.7.0)\n",
            "Collecting anthropic==0.43.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 5))\n",
            "  Downloading anthropic-0.43.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting anyio==4.8.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 9))\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting asyncer==0.0.8 (from -r /content/Agent-E-master_xxx/requirements.txt (line 19))\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting autogen==0.7.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 21))\n",
            "  Downloading autogen-0.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting cachetools==5.5.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 23))\n",
            "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting certifi==2024.12.14 (from -r /content/Agent-E-master_xxx/requirements.txt (line 25))\n",
            "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: cffi==1.17.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 30)) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 32)) (3.4.1)\n",
            "Requirement already satisfied: click==8.1.8 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 36)) (8.1.8)\n",
            "Collecting cryptography==44.0.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 42))\n",
            "  Downloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting diskcache==5.6.3 (from -r /content/Agent-E-master_xxx/requirements.txt (line 44))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 46)) (1.9.0)\n",
            "Collecting dnspython==2.7.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 51))\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting docker==7.1.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 53))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting email-validator==2.2.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 55))\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting fast-depends==2.4.12 (from -r /content/Agent-E-master_xxx/requirements.txt (line 57))\n",
            "  Downloading fast_depends-2.4.12-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting fastapi==0.111.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 59))\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting fastapi-cli==0.0.7 (from -r /content/Agent-E-master_xxx/requirements.txt (line 61))\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting flaml==2.3.3 (from -r /content/Agent-E-master_xxx/requirements.txt (line 63))\n",
            "  Downloading FLAML-2.3.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.2 (from -r /content/Agent-E-master_xxx/requirements.txt (line 65))\n",
            "  Downloading google_ai_generativelanguage-0.6.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting google-api-core==2.24.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 67))\n",
            "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-api-python-client==2.159.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 72))\n",
            "  Downloading google_api_python_client-2.159.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting google-auth==2.37.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 74))\n",
            "  Downloading google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: google-auth-httplib2==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 82)) (0.2.0)\n",
            "Collecting google-generativeai==0.5.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 84))\n",
            "  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting googleapis-common-protos==1.66.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 86))\n",
            "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting greenlet==3.0.3 (from -r /content/Agent-E-master_xxx/requirements.txt (line 90))\n",
            "  Downloading greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting groq==0.15.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 92))\n",
            "  Downloading groq-0.15.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting grpcio==1.69.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 94))\n",
            "  Downloading grpcio-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting grpcio-status==1.62.3 (from -r /content/Agent-E-master_xxx/requirements.txt (line 98))\n",
            "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: h11==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 100)) (0.14.0)\n",
            "Requirement already satisfied: httpcore==1.0.7 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 104)) (1.0.7)\n",
            "Requirement already satisfied: httplib2==0.22.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 106)) (0.22.0)\n",
            "Collecting httptools==0.6.4 (from -r /content/Agent-E-master_xxx/requirements.txt (line 110))\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 112)) (0.28.1)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 118)) (3.10)\n",
            "Collecting jinja2==3.1.5 (from -r /content/Agent-E-master_xxx/requirements.txt (line 124))\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting jiter==0.8.2 (from -r /content/Agent-E-master_xxx/requirements.txt (line 126))\n",
            "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 130)) (1.4.2)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 132)) (3.0.0)\n",
            "Requirement already satisfied: markupsafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 134)) (3.0.2)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 136)) (0.1.2)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 138)) (1.6.0)\n",
            "Collecting nltk==3.8.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 140))\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting numpy==1.26.4 (from -r /content/Agent-E-master_xxx/requirements.txt (line 142))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==1.59.7 (from -r /content/Agent-E-master_xxx/requirements.txt (line 146))\n",
            "  Downloading openai-1.59.7-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 148)) (24.2)\n",
            "Collecting pdfminer-six==20231228 (from -r /content/Agent-E-master_xxx/requirements.txt (line 150))\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pdfplumber==0.11.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 152))\n",
            "  Downloading pdfplumber-0.11.1-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: pillow==11.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 154)) (11.1.0)\n",
            "Collecting playwright==1.44.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 156))\n",
            "  Downloading playwright-1.44.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting proto-plus==1.25.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 158))\n",
            "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting protobuf==4.25.5 (from -r /content/Agent-E-master_xxx/requirements.txt (line 162))\n",
            "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: pyasn1==0.6.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 170)) (0.6.1)\n",
            "Collecting pyasn1-modules==0.4.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 174))\n",
            "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pyautogen==0.7.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 176))\n",
            "  Downloading pyautogen-0.7.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pycparser==2.22 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 178)) (2.22)\n",
            "Collecting pydantic==2.6.2 (from -r /content/Agent-E-master_xxx/requirements.txt (line 180))\n",
            "  Downloading pydantic-2.6.2-py3-none-any.whl.metadata (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.16.3 (from -r /content/Agent-E-master_xxx/requirements.txt (line 190))\n",
            "  Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pyee==11.1.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 192))\n",
            "  Downloading pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting pygments==2.19.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 194))\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pyparsing==3.2.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 196))\n",
            "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pypdfium2==4.30.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 198))\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv==1.0.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 200))\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting python-json-logger==2.0.7 (from -r /content/Agent-E-master_xxx/requirements.txt (line 205))\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-multipart==0.0.20 (from -r /content/Agent-E-master_xxx/requirements.txt (line 207))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 209)) (6.0.2)\n",
            "Requirement already satisfied: regex==2024.11.6 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 211)) (2024.11.6)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 215)) (2.32.3)\n",
            "Requirement already satisfied: rich==13.9.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 220)) (13.9.4)\n",
            "Collecting rich-toolkit==0.13.2 (from -r /content/Agent-E-master_xxx/requirements.txt (line 224))\n",
            "  Downloading rich_toolkit-0.13.2-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 226)) (4.9)\n",
            "Requirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 228)) (1.5.4)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 230)) (1.3.1)\n",
            "Collecting starlette==0.37.2 (from -r /content/Agent-E-master_xxx/requirements.txt (line 236))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 238)) (0.9.0)\n",
            "Collecting termcolor==2.5.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 240))\n",
            "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting tiktoken==0.8.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 242))\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 244)) (4.67.1)\n",
            "Collecting typer==0.15.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 249))\n",
            "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting typing-extensions==4.12.2 (from -r /content/Agent-E-master_xxx/requirements.txt (line 251))\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: uritemplate==4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 264)) (4.1.1)\n",
            "Requirement already satisfied: urllib3==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/Agent-E-master_xxx/requirements.txt (line 266)) (2.3.0)\n",
            "Collecting uvicorn==0.30.3 (from -r /content/Agent-E-master_xxx/requirements.txt (line 270))\n",
            "  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting uvloop==0.21.0 (from -r /content/Agent-E-master_xxx/requirements.txt (line 275))\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles==1.0.4 (from -r /content/Agent-E-master_xxx/requirements.txt (line 277))\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets==14.1 (from -r /content/Agent-E-master_xxx/requirements.txt (line 279))\n",
            "  Downloading websockets-14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "\u001b[31mERROR: Cannot install httpcore==0.16.3 and httpcore==1.0.7 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested httpcore==1.0.7\n",
            "    The user requested httpcore==0.16.3\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0mObtaining file:///content/Agent-E-master_xxx\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 538, in collect_root_requirements\n",
            "    reqs = list(\n",
            "           ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 494, in _make_requirements_from_install_req\n",
            "    cand = self._make_base_candidate_from_link(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 210, in _make_base_candidate_from_link\n",
            "    self._editable_candidate_cache[link] = EditableCandidate(\n",
            "                                           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 328, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 338, in _prepare_distribution\n",
            "    return self._factory.preparer.prepare_editable_requirement(self._ireq)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 698, in prepare_editable_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/distributions/sdist.py\", line 54, in prepare_distribution_metadata\n",
            "    self.req.isolated_editable_sanity_check()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_install.py\", line 540, in isolated_editable_sanity_check\n",
            "    and not self.supports_pyproject_editable\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/functools.py\", line 1001, in __get__\n",
            "    val = self.func(instance)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_install.py\", line 257, in supports_pyproject_editable\n",
            "    return \"build_editable\" in self.pep517_backend._supported_features()\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 153, in _supported_features\n",
            "    return self._call_hook('_supported_features', {})\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 321, in _call_hook\n",
            "    raise BackendUnavailable(data.get('traceback', ''))\n",
            "pip._vendor.pyproject_hooks._impl.BackendUnavailable: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 77, in _build_backend\n",
            "    obj = import_module(mod_path)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1140, in _find_and_load_unlocked\n",
            "ModuleNotFoundError: No module named 'uv.build_api'\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Python libraries\n",
        "!pip install -r /content/impress.txt\n",
        "\n",
        "# Install the Agent-E project as a package\n",
        "%pip install -e /content/Agent-E-master_xxx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S_8Lh9HTs1do",
        "outputId": "d9b649af-4f52-414e-8c0f-8d2c4bcc6657"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 3)) (0.7.0)\n",
            "Collecting anthropic==0.43.0 (from -r /content/impress.txt (line 5))\n",
            "  Using cached anthropic-0.43.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting anyio==4.8.0 (from -r /content/impress.txt (line 9))\n",
            "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting asyncer==0.0.8 (from -r /content/impress.txt (line 19))\n",
            "  Using cached asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting autogen==0.7.0 (from -r /content/impress.txt (line 21))\n",
            "  Using cached autogen-0.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting cachetools==5.5.0 (from -r /content/impress.txt (line 23))\n",
            "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting certifi==2024.12.14 (from -r /content/impress.txt (line 25))\n",
            "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: cffi==1.17.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 30)) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 32)) (3.4.1)\n",
            "Requirement already satisfied: click==8.1.8 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 36)) (8.1.8)\n",
            "Collecting cryptography==44.0.0 (from -r /content/impress.txt (line 42))\n",
            "  Using cached cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting diskcache==5.6.3 (from -r /content/impress.txt (line 44))\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 46)) (1.9.0)\n",
            "Collecting dnspython==2.7.0 (from -r /content/impress.txt (line 51))\n",
            "  Using cached dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting docker==7.1.0 (from -r /content/impress.txt (line 53))\n",
            "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting email-validator==2.2.0 (from -r /content/impress.txt (line 55))\n",
            "  Using cached email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting fast-depends==2.4.12 (from -r /content/impress.txt (line 57))\n",
            "  Using cached fast_depends-2.4.12-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting fastapi==0.111.1 (from -r /content/impress.txt (line 59))\n",
            "  Using cached fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting fastapi-cli==0.0.7 (from -r /content/impress.txt (line 61))\n",
            "  Using cached fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting flaml==2.3.3 (from -r /content/impress.txt (line 63))\n",
            "  Using cached FLAML-2.3.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.2 (from -r /content/impress.txt (line 65))\n",
            "  Using cached google_ai_generativelanguage-0.6.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting google-api-core==2.24.0 (from -r /content/impress.txt (line 67))\n",
            "  Using cached google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-api-python-client==2.159.0 (from -r /content/impress.txt (line 72))\n",
            "  Using cached google_api_python_client-2.159.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting google-auth==2.37.0 (from -r /content/impress.txt (line 74))\n",
            "  Using cached google_auth-2.37.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: google-auth-httplib2==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 82)) (0.2.0)\n",
            "Collecting google-generativeai==0.5.1 (from -r /content/impress.txt (line 84))\n",
            "  Using cached google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting googleapis-common-protos==1.66.0 (from -r /content/impress.txt (line 86))\n",
            "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting greenlet==3.0.3 (from -r /content/impress.txt (line 90))\n",
            "  Using cached greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting groq==0.15.0 (from -r /content/impress.txt (line 92))\n",
            "  Using cached groq-0.15.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting grpcio==1.69.0 (from -r /content/impress.txt (line 94))\n",
            "  Using cached grpcio-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting grpcio-status==1.62.3 (from -r /content/impress.txt (line 98))\n",
            "  Using cached grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: h11==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 100)) (0.14.0)\n",
            "Requirement already satisfied: httpcore==1.0.7 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 104)) (1.0.7)\n",
            "Requirement already satisfied: httplib2==0.22.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 106)) (0.22.0)\n",
            "Collecting httptools==0.6.4 (from -r /content/impress.txt (line 110))\n",
            "  Using cached httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 112)) (0.28.1)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 118)) (3.10)\n",
            "Collecting jinja2==3.1.5 (from -r /content/impress.txt (line 124))\n",
            "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting jiter==0.8.2 (from -r /content/impress.txt (line 126))\n",
            "  Using cached jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 130)) (1.4.2)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 132)) (3.0.0)\n",
            "Requirement already satisfied: markupsafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 134)) (3.0.2)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 136)) (0.1.2)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 138)) (1.6.0)\n",
            "Collecting nltk==3.8.1 (from -r /content/impress.txt (line 140))\n",
            "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting numpy==1.26.4 (from -r /content/impress.txt (line 142))\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting openai==1.59.7 (from -r /content/impress.txt (line 146))\n",
            "  Using cached openai-1.59.7-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 148)) (24.2)\n",
            "Collecting pdfminer-six==20231228 (from -r /content/impress.txt (line 150))\n",
            "  Using cached pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting pdfplumber==0.11.1 (from -r /content/impress.txt (line 152))\n",
            "  Using cached pdfplumber-0.11.1-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: pillow==11.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 154)) (11.1.0)\n",
            "Collecting playwright==1.44.0 (from -r /content/impress.txt (line 156))\n",
            "  Using cached playwright-1.44.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting proto-plus==1.25.0 (from -r /content/impress.txt (line 158))\n",
            "  Using cached proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting protobuf==4.25.5 (from -r /content/impress.txt (line 162))\n",
            "  Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: pyasn1==0.6.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 170)) (0.6.1)\n",
            "Collecting pyasn1-modules==0.4.1 (from -r /content/impress.txt (line 174))\n",
            "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting pyautogen==0.7.0 (from -r /content/impress.txt (line 176))\n",
            "  Using cached pyautogen-0.7.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pycparser==2.22 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 178)) (2.22)\n",
            "Collecting pydantic==2.6.2 (from -r /content/impress.txt (line 180))\n",
            "  Using cached pydantic-2.6.2-py3-none-any.whl.metadata (83 kB)\n",
            "Collecting pydantic-core==2.16.3 (from -r /content/impress.txt (line 190))\n",
            "  Using cached pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pyee==11.1.0 (from -r /content/impress.txt (line 192))\n",
            "  Using cached pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting pygments==2.19.1 (from -r /content/impress.txt (line 194))\n",
            "  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pyparsing==3.2.1 (from -r /content/impress.txt (line 196))\n",
            "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting pypdfium2==4.30.1 (from -r /content/impress.txt (line 198))\n",
            "  Using cached pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "Collecting python-dotenv==1.0.0 (from -r /content/impress.txt (line 200))\n",
            "  Using cached python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting python-json-logger==2.0.7 (from -r /content/impress.txt (line 205))\n",
            "  Using cached python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-multipart==0.0.20 (from -r /content/impress.txt (line 207))\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 209)) (6.0.2)\n",
            "Requirement already satisfied: regex==2024.11.6 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 211)) (2024.11.6)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 215)) (2.32.3)\n",
            "Requirement already satisfied: rich==13.9.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 220)) (13.9.4)\n",
            "Collecting rich-toolkit==0.13.2 (from -r /content/impress.txt (line 224))\n",
            "  Using cached rich_toolkit-0.13.2-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 226)) (4.9)\n",
            "Requirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 228)) (1.5.4)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 230)) (1.3.1)\n",
            "Collecting starlette==0.37.2 (from -r /content/impress.txt (line 236))\n",
            "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 238)) (0.9.0)\n",
            "Collecting termcolor==2.5.0 (from -r /content/impress.txt (line 240))\n",
            "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting tiktoken==0.8.0 (from -r /content/impress.txt (line 242))\n",
            "  Using cached tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 244)) (4.67.1)\n",
            "Collecting typer==0.15.1 (from -r /content/impress.txt (line 249))\n",
            "  Using cached typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting typing-extensions==4.12.2 (from -r /content/impress.txt (line 251))\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: uritemplate==4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 264)) (4.1.1)\n",
            "Requirement already satisfied: urllib3==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 266)) (2.3.0)\n",
            "Collecting uvicorn==0.30.3 (from -r /content/impress.txt (line 270))\n",
            "  Using cached uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting uvloop==0.21.0 (from -r /content/impress.txt (line 275))\n",
            "  Using cached uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles==1.0.4 (from -r /content/impress.txt (line 277))\n",
            "  Using cached watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets==14.1 (from -r /content/impress.txt (line 279))\n",
            "  Using cached websockets-14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Downloading anthropic-0.43.0-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.9/207.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading autogen-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cryptography-44.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fast_depends-2.4.12-py3-none-any.whl (17 kB)\n",
            "Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading FLAML-2.3.3-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.2/314.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_ai_generativelanguage-0.6.2-py3-none-any.whl (664 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.5/664.5 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_core-2.24.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_api_python_client-2.159.0-py2.py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.37.0-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_generativeai-0.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.2/142.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.7/221.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (620 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.0/620.0 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.15.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.59.7-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading playwright-1.44.0-py3-none-manylinux1_x86_64.whl (37.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyautogen-0.7.0-py3-none-any.whl (497 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.3/497.3 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.6.2-py3-none-any.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading rich_toolkit-0.13.2-py3-none-any.whl (13 kB)\n",
            "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.8/168.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, uvloop, uvicorn, typing-extensions, termcolor, python-multipart, python-json-logger, python-dotenv, pypdfium2, pyparsing, pygments, pyasn1-modules, protobuf, numpy, nltk, jiter, jinja2, httptools, grpcio, greenlet, dnspython, diskcache, certifi, cachetools, pyee, pydantic-core, proto-plus, googleapis-common-protos, google-auth, flaml, email-validator, cryptography, anyio, watchfiles, typer, tiktoken, starlette, rich-toolkit, pydantic, playwright, pdfminer-six, grpcio-status, google-api-core, docker, asyncer, pdfplumber, openai, groq, google-api-python-client, fast-depends, anthropic, pyautogen, google-ai-generativelanguage, fastapi-cli, google-generativeai, fastapi, autogen\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.0\n",
            "    Uninstalling typing_extensions-4.13.0:\n",
            "      Successfully uninstalled typing_extensions-4.13.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.0.1\n",
            "    Uninstalling termcolor-3.0.1:\n",
            "      Successfully uninstalled termcolor-3.0.1\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.3\n",
            "    Uninstalling pyparsing-3.2.3:\n",
            "      Successfully uninstalled pyparsing-3.2.3\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.18.0\n",
            "    Uninstalling Pygments-2.18.0:\n",
            "      Successfully uninstalled Pygments-2.18.0\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.9.0\n",
            "    Uninstalling jiter-0.9.0:\n",
            "      Successfully uninstalled jiter-0.9.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 3.1.1\n",
            "    Uninstalling greenlet-3.1.1:\n",
            "      Successfully uninstalled greenlet-3.1.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.0\n",
            "    Uninstalling pydantic_core-2.33.0:\n",
            "      Successfully uninstalled pydantic_core-2.33.0\n",
            "  Attempting uninstall: proto-plus\n",
            "    Found existing installation: proto-plus 1.26.1\n",
            "    Uninstalling proto-plus-1.26.1:\n",
            "      Successfully uninstalled proto-plus-1.26.1\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.69.2\n",
            "    Uninstalling googleapis-common-protos-1.69.2:\n",
            "      Successfully uninstalled googleapis-common-protos-1.69.2\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.38.0\n",
            "    Uninstalling google-auth-2.38.0:\n",
            "      Successfully uninstalled google-auth-2.38.0\n",
            "  Attempting uninstall: cryptography\n",
            "    Found existing installation: cryptography 43.0.3\n",
            "    Uninstalling cryptography-43.0.3:\n",
            "      Successfully uninstalled cryptography-43.0.3\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 4.9.0\n",
            "    Uninstalling anyio-4.9.0:\n",
            "      Successfully uninstalled anyio-4.9.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.15.2\n",
            "    Uninstalling typer-0.15.2:\n",
            "      Successfully uninstalled typer-0.15.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.1\n",
            "    Uninstalling pydantic-2.11.1:\n",
            "      Successfully uninstalled pydantic-2.11.1\n",
            "  Attempting uninstall: grpcio-status\n",
            "    Found existing installation: grpcio-status 1.71.0\n",
            "    Uninstalling grpcio-status-1.71.0:\n",
            "      Successfully uninstalled grpcio-status-1.71.0\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.24.2\n",
            "    Uninstalling google-api-core-2.24.2:\n",
            "      Successfully uninstalled google-api-core-2.24.2\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.70.0\n",
            "    Uninstalling openai-1.70.0:\n",
            "      Successfully uninstalled openai-1.70.0\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.164.0\n",
            "    Uninstalling google-api-python-client-2.164.0:\n",
            "      Successfully uninstalled google-api-python-client-2.164.0\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.8.4\n",
            "    Uninstalling google-generativeai-0.8.4:\n",
            "      Successfully uninstalled google-generativeai-0.8.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.37.0 which is incompatible.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 2.6.2 which is incompatible.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.0 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.0 which is incompatible.\n",
            "langchain 0.3.22 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.6.2 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anthropic-0.43.0 anyio-4.8.0 asyncer-0.0.8 autogen-0.7.0 cachetools-5.5.0 certifi-2024.12.14 cryptography-44.0.0 diskcache-5.6.3 dnspython-2.7.0 docker-7.1.0 email-validator-2.2.0 fast-depends-2.4.12 fastapi-0.111.1 fastapi-cli-0.0.7 flaml-2.3.3 google-ai-generativelanguage-0.6.2 google-api-core-2.24.0 google-api-python-client-2.159.0 google-auth-2.37.0 google-generativeai-0.5.1 googleapis-common-protos-1.66.0 greenlet-3.0.3 groq-0.15.0 grpcio-1.69.0 grpcio-status-1.62.3 httptools-0.6.4 jinja2-3.1.5 jiter-0.8.2 nltk-3.8.1 numpy-1.26.4 openai-1.59.7 pdfminer-six-20231228 pdfplumber-0.11.1 playwright-1.44.0 proto-plus-1.25.0 protobuf-4.25.5 pyasn1-modules-0.4.1 pyautogen-0.7.0 pydantic-2.6.2 pydantic-core-2.16.3 pyee-11.1.0 pygments-2.19.1 pyparsing-3.2.1 pypdfium2-4.30.1 python-dotenv-1.0.0 python-json-logger-2.0.7 python-multipart-0.0.20 rich-toolkit-0.13.2 starlette-0.37.2 termcolor-2.5.0 tiktoken-0.8.0 typer-0.15.1 typing-extensions-4.12.2 uvicorn-0.30.3 uvloop-0.21.0 watchfiles-1.0.4 websockets-14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "google"
                ]
              },
              "id": "b661dc5ff2a74f3daf7f2061514fb5a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/Agent-E-master_xxx\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 76, in resolve\n",
            "    collected = self.factory.collect_root_requirements(root_reqs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 538, in collect_root_requirements\n",
            "    reqs = list(\n",
            "           ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 494, in _make_requirements_from_install_req\n",
            "    cand = self._make_base_candidate_from_link(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 210, in _make_base_candidate_from_link\n",
            "    self._editable_candidate_cache[link] = EditableCandidate(\n",
            "                                           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 328, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 338, in _prepare_distribution\n",
            "    return self._factory.preparer.prepare_editable_requirement(self._ireq)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 698, in prepare_editable_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/distributions/sdist.py\", line 54, in prepare_distribution_metadata\n",
            "    self.req.isolated_editable_sanity_check()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_install.py\", line 540, in isolated_editable_sanity_check\n",
            "    and not self.supports_pyproject_editable\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/functools.py\", line 1001, in __get__\n",
            "    val = self.func(instance)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/req/req_install.py\", line 257, in supports_pyproject_editable\n",
            "    return \"build_editable\" in self.pep517_backend._supported_features()\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 153, in _supported_features\n",
            "    return self._call_hook('_supported_features', {})\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 321, in _call_hook\n",
            "    raise BackendUnavailable(data.get('traceback', ''))\n",
            "pip._vendor.pyproject_hooks._impl.BackendUnavailable: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 77, in _build_backend\n",
            "    obj = import_module(mod_path)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1140, in _find_and_load_unlocked\n",
            "ModuleNotFoundError: No module named 'uv.build_api'\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall uv if it's corrupt\n",
        "!pip uninstall -y uv\n",
        "\n",
        "# Force reinstall pip with older backend and patch setuptools\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "\n",
        "# OPTIONAL: Just in case something forced `uv` as backend\n",
        "!pip install build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "iinzcdmuwegx",
        "outputId": "ce07656c-69bc-4f84-85f4-349e22eefb2b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping uv as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (0.45.1)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-25.0.1 setuptools-78.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "87ca6081ee2542c181adf5ef23a7178d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting build\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build) (24.2)\n",
            "Collecting pyproject_hooks (from build)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: pyproject_hooks, build\n",
            "Successfully installed build-1.2.2.post1 pyproject_hooks-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Overwrite pyproject.toml with setuptools and wheel (instead of uv.build_api)\n",
        "with open(\"/content/Agent-E-master_xxx/pyproject.toml\", \"w\") as f:\n",
        "    f.write(\"\"\"[build-system]\n",
        "requires = [\"setuptools\", \"wheel\"]\n",
        "build-backend = \"setuptools.build_meta\"\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "6JTqj-U_xq2h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Print the file to confirm changes\n",
        "!cat /content/Agent-E-master_xxx/pyproject.toml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZvvFKS-zT25",
        "outputId": "3d585b43-3c00-445c-8668-9887f6f6b587"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[build-system]\n",
            "requires = [\"setuptools\", \"wheel\"]\n",
            "build-backend = \"setuptools.build_meta\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/impress.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QO0dENEwzW_L",
        "outputId": "bbea0802-fc7b-4147-d924-f57a499e2c0c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: anthropic==0.43.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 5)) (0.43.0)\n",
            "Requirement already satisfied: anyio==4.8.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 9)) (4.8.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 19)) (0.0.8)\n",
            "Requirement already satisfied: autogen==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 21)) (0.7.0)\n",
            "Requirement already satisfied: cachetools==5.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 23)) (5.5.0)\n",
            "Requirement already satisfied: certifi==2024.12.14 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 25)) (2024.12.14)\n",
            "Requirement already satisfied: cffi==1.17.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 30)) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 32)) (3.4.1)\n",
            "Requirement already satisfied: click==8.1.8 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 36)) (8.1.8)\n",
            "Requirement already satisfied: cryptography==44.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 42)) (44.0.0)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 44)) (5.6.3)\n",
            "Requirement already satisfied: distro==1.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 46)) (1.9.0)\n",
            "Requirement already satisfied: dnspython==2.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 51)) (2.7.0)\n",
            "Requirement already satisfied: docker==7.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 53)) (7.1.0)\n",
            "Requirement already satisfied: email-validator==2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 55)) (2.2.0)\n",
            "Requirement already satisfied: fast-depends==2.4.12 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 57)) (2.4.12)\n",
            "Requirement already satisfied: fastapi==0.111.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 59)) (0.111.1)\n",
            "Requirement already satisfied: fastapi-cli==0.0.7 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 61)) (0.0.7)\n",
            "Requirement already satisfied: flaml==2.3.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 63)) (2.3.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 65)) (0.6.2)\n",
            "Requirement already satisfied: google-api-core==2.24.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 67)) (2.24.0)\n",
            "Requirement already satisfied: google-api-python-client==2.159.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 72)) (2.159.0)\n",
            "Requirement already satisfied: google-auth==2.37.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 74)) (2.37.0)\n",
            "Requirement already satisfied: google-auth-httplib2==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 82)) (0.2.0)\n",
            "Requirement already satisfied: google-generativeai==0.5.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 84)) (0.5.1)\n",
            "Requirement already satisfied: googleapis-common-protos==1.66.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 86)) (1.66.0)\n",
            "Requirement already satisfied: greenlet==3.0.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 90)) (3.0.3)\n",
            "Requirement already satisfied: groq==0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 92)) (0.15.0)\n",
            "Requirement already satisfied: grpcio==1.69.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 94)) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status==1.62.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 98)) (1.62.3)\n",
            "Requirement already satisfied: h11==0.14.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 100)) (0.14.0)\n",
            "Requirement already satisfied: httpcore==1.0.7 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 104)) (1.0.7)\n",
            "Requirement already satisfied: httplib2==0.22.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 106)) (0.22.0)\n",
            "Requirement already satisfied: httptools==0.6.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 110)) (0.6.4)\n",
            "Requirement already satisfied: httpx==0.28.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 112)) (0.28.1)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 118)) (3.10)\n",
            "Requirement already satisfied: jinja2==3.1.5 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 124)) (3.1.5)\n",
            "Requirement already satisfied: jiter==0.8.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 126)) (0.8.2)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 130)) (1.4.2)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 132)) (3.0.0)\n",
            "Requirement already satisfied: markupsafe==3.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 134)) (3.0.2)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 136)) (0.1.2)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 138)) (1.6.0)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 140)) (3.8.1)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 142)) (1.26.4)\n",
            "Requirement already satisfied: openai==1.59.7 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 146)) (1.59.7)\n",
            "Requirement already satisfied: packaging==24.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 148)) (24.2)\n",
            "Requirement already satisfied: pdfminer-six==20231228 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 150)) (20231228)\n",
            "Requirement already satisfied: pdfplumber==0.11.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 152)) (0.11.1)\n",
            "Requirement already satisfied: pillow==11.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 154)) (11.1.0)\n",
            "Requirement already satisfied: playwright==1.44.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 156)) (1.44.0)\n",
            "Requirement already satisfied: proto-plus==1.25.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 158)) (1.25.0)\n",
            "Requirement already satisfied: protobuf==4.25.5 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 162)) (4.25.5)\n",
            "Requirement already satisfied: pyasn1==0.6.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 170)) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules==0.4.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 174)) (0.4.1)\n",
            "Requirement already satisfied: pyautogen==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 176)) (0.7.0)\n",
            "Requirement already satisfied: pycparser==2.22 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 178)) (2.22)\n",
            "Requirement already satisfied: pydantic==2.6.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 180)) (2.6.2)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 190)) (2.16.3)\n",
            "Requirement already satisfied: pyee==11.1.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 192)) (11.1.0)\n",
            "Requirement already satisfied: pygments==2.19.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 194)) (2.19.1)\n",
            "Requirement already satisfied: pyparsing==3.2.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 196)) (3.2.1)\n",
            "Requirement already satisfied: pypdfium2==4.30.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 198)) (4.30.1)\n",
            "Requirement already satisfied: python-dotenv==1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 200)) (1.0.0)\n",
            "Requirement already satisfied: python-json-logger==2.0.7 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 205)) (2.0.7)\n",
            "Requirement already satisfied: python-multipart==0.0.20 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 207)) (0.0.20)\n",
            "Requirement already satisfied: pyyaml==6.0.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 209)) (6.0.2)\n",
            "Requirement already satisfied: regex==2024.11.6 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 211)) (2024.11.6)\n",
            "Requirement already satisfied: requests==2.32.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 215)) (2.32.3)\n",
            "Requirement already satisfied: rich==13.9.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 220)) (13.9.4)\n",
            "Requirement already satisfied: rich-toolkit==0.13.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 224)) (0.13.2)\n",
            "Requirement already satisfied: rsa==4.9 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 226)) (4.9)\n",
            "Requirement already satisfied: shellingham==1.5.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 228)) (1.5.4)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 230)) (1.3.1)\n",
            "Requirement already satisfied: starlette==0.37.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 236)) (0.37.2)\n",
            "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 238)) (0.9.0)\n",
            "Requirement already satisfied: termcolor==2.5.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 240)) (2.5.0)\n",
            "Requirement already satisfied: tiktoken==0.8.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 242)) (0.8.0)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 244)) (4.67.1)\n",
            "Requirement already satisfied: typer==0.15.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 249)) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions==4.12.2 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 251)) (4.12.2)\n",
            "Requirement already satisfied: uritemplate==4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 264)) (4.1.1)\n",
            "Requirement already satisfied: urllib3==2.3.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 266)) (2.3.0)\n",
            "Requirement already satisfied: uvicorn==0.30.3 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 270)) (0.30.3)\n",
            "Requirement already satisfied: uvloop==0.21.0 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 275)) (0.21.0)\n",
            "Requirement already satisfied: watchfiles==1.0.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 277)) (1.0.4)\n",
            "Requirement already satisfied: websockets==14.1 in /usr/local/lib/python3.11/dist-packages (from -r /content/impress.txt (line 279)) (14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔑 Configure API keys and model\n",
        "import os\n",
        "os.environ[\"AUTOGEN_MODEL_API_KEY\"] = \"cb9cac225amshf0ccd5867ef7942p159e93jsncd4b0385f515\"  # Replace with your RapidAPI key\n",
        "os.environ[\"AUTOGEN_MODEL_NAME\"] = \"mixtral8x7b\"           # Model name (example)\n",
        "# If using a separate key for job search API (usually not required), also set:\n",
        "# os.environ[\"JOB_API_KEY\"] = \"<YOUR_RAPIDAPI_KEY_FOR_JSEARCH>\""
      ],
      "metadata": {
        "id": "oAvpil840D_u"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "resume_path = \"/content/resume.pdf\"  # TODO: change to your resume file path in Drive\n",
        "with pdfplumber.open(resume_path) as pdf:\n",
        "    resume_text = \"\"\n",
        "    for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            resume_text += text + \"\\n\"\n",
        "\n",
        "resume_text = resume_text.strip()\n",
        "print(\"Resume text length:\", len(resume_text), \"characters\")\n",
        "print(resume_text[:500], \"...\")  # preview first 500 characters\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr8jyFAm4xqM",
        "outputId": "7d94a5e7-485a-4796-8651-2b6672840c11"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume text length: 1646 characters\n",
            "Yash Agrawal\n",
            "iiityash@gmail.com | +91 8218469891 | inkedin.com/in/yash-agrawal-18486a145 | India\n",
            "MotivatedIntellectual aspiring tofollow passioninbuilding robustwebappsand DataScience\n",
            "projects, livesinBangalore.\n",
            "EDUCATION: IIIT Gwalior [2017 - 2022]\n",
            "Post Graduation: IntegratedDualDegree (B.Tech + MBA)inIT\n",
            "HackerRank : 10,001(As of2023)\n",
            "EXPERIENCE: IVTREE, Bangalore\n",
            "(Building RobustWeb appsusing RESTAPI) (05/2023- TillDate)\n",
            "PROJECTS: Deep Learning ( DL ) To Predict ElectroCardiGram - Python\n",
            "A mod ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ae.core.skills.extract_keywords import extract_keywords\n",
        "\n",
        "keywords = extract_keywords(resume_text, top_n=10)\n",
        "print(\"Extracted keywords:\", keywords)\n",
        "#my module is in : /content/Agent-E-master_xxx/ae/core/skills/extract_keywords.py, from which extract_keywords is to be used, now what to do"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "AgECSRBE5aN1",
        "outputId": "1419dd2c-3c4a-4223-bd9f-b5d47237f242"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/tune/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mray_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9f0ce14837dc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskills\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_keywords\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracted keywords:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#my module is in : /content/Agent-E-master_xxx/ae/core/skills/extract_keywords.py, from which extract_keywords is to be used, now what to do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m  \u001b[0;31m# type: ignore # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautogen_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutogenWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaywright_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlaywrightManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/core/agents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrowser_nav_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrowserNavAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/core/agents/browser_nav_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mautogen\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_ltm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_user_ltm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0magentchat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcode_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDEFAULT_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAST_MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexception_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/agentchat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# SPDX-License-Identifier: MIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0massistant_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAssistantAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitiate_chats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m from .contrib.reasoning_agent import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/agentchat/assistant_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntime_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog_new_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconversable_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConversableAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_dump\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m from ..code_utils import (\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mPYTHON_VARIANTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mUNKNOWN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/code_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUserMessageImageContentPart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserMessageTextContentPart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/oai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAIWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatCompletion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompletion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m from autogen.oai.openai_utils import (\n\u001b[1;32m     11\u001b[0m     \u001b[0mconfig_list_from_dotenv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/oai/completion.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mflaml_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnull_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBlendSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_formatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhas_automl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/automl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoMLState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSearchState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/automl/automl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_formatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhuggingface_metric_to_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn_metric_name_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark_metric_name_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/tune/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     from .sample import (\n\u001b[1;32m     25\u001b[0m         \u001b[0mlograndint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/tune/sample.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Added in numpy>=1.17 but we require numpy>=1.16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mnp_random_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mLEGACY_RNG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/Agent-E-master_xxx')"
      ],
      "metadata": {
        "id": "bXvR4TcI6WXg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5 flaml==2.1.1 scikit-learn==1.1.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "iO9YBazw5geR",
        "outputId": "7f4e8621-0bc0-4931-e003-f7a0bc05d9af"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting flaml==2.1.1\n",
            "  Downloading FLAML-2.1.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting scikit-learn==1.1.3\n",
            "  Downloading scikit_learn-1.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.1.3) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.1.3) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.1.3) (3.6.0)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.1.1-py3-none-any.whl (295 kB)\n",
            "Downloading scikit_learn-1.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.0/32.0 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, flaml, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: flaml\n",
            "    Found existing installation: FLAML 2.3.3\n",
            "    Uninstalling FLAML-2.3.3:\n",
            "      Successfully uninstalled FLAML-2.3.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyautogen 0.7.0 requires numpy<2.0.0,>=1.24.0; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 2.6.2 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.1.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flaml-2.1.1 numpy-1.23.5 scikit-learn-1.1.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "0291dce43413446dbd0753b69277ab2e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.4 scikit-learn==1.2.2 flaml==2.1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "sH9DvDrn8dDE",
        "outputId": "0325eb43-7c5e-4609-d841-9048de16c7bc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: flaml==2.1.1 in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\n",
            "Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scikit-learn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.1.3\n",
            "    Uninstalling scikit-learn-1.1.3:\n",
            "      Successfully uninstalled scikit-learn-1.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 2.6.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4 scikit-learn-1.2.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "ca2ba5d4d80643e78628a508f0619461"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.25.2 scikit-learn==1.3.2 flaml==2.1.1 jax==0.4.13 jaxlib==0.4.13 tensorflow==2.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba5zK4vh85nv",
        "outputId": "83250870-d469-46e8-b29e-a041fe606934"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.25.2\n",
            "  Downloading numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting scikit-learn==1.3.2\n",
            "  Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: flaml==2.1.1 in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Collecting jax==0.4.13\n",
            "  Downloading jax-0.4.13.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jaxlib==0.4.13\n",
            "  Downloading jaxlib-0.4.13-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (3.6.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from jax==0.4.13) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax==0.4.13) (3.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (1.69.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (3.13.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13.0) (18.1.1)\n",
            "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting flaml==2.1.1\n",
            "  Using cached FLAML-2.1.1-py3-none-any.whl.metadata (15 kB)\n",
            "\u001b[31mERROR: Cannot install flaml==2.1.1, jax==0.4.13, jaxlib==0.4.13, numpy==1.25.2, scikit-learn==1.3.2 and tensorflow==2.13.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested numpy==1.25.2\n",
            "    scikit-learn 1.3.2 depends on numpy<2.0 and >=1.17.3\n",
            "    flaml 2.1.1 depends on NumPy>=1.17.0rc1\n",
            "    jax 0.4.13 depends on numpy>=1.21\n",
            "    jaxlib 0.4.13 depends on numpy>=1.21\n",
            "    tensorflow 2.13.0 depends on numpy<=1.24.3 and >=1.22\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CORE safe versions\n",
        "!pip install numpy==1.24.3 scikit-learn==1.2.2 flaml==2.1.1 jax==0.4.13 jaxlib==0.4.13 tensorflow==2.12.0 pandas==1.5.3 openai==1.2.3 nest_asyncio==1.5.8 python-dotenv==1.0.0 requests==2.31.0 beautifulsoup4==4.12.2 tqdm==4.66.1 lxml==4.9.3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wiovl4Ez9V5E",
        "outputId": "ef646e7c-fa91-4c44-a22b-796dda0e327d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: flaml==2.1.1 in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Collecting jax==0.4.13\n",
            "  Using cached jax-0.4.13.tar.gz (1.3 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jaxlib==0.4.13\n",
            "  Using cached jaxlib-0.4.13-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting openai==1.2.3\n",
            "  Downloading openai-1.2.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting nest_asyncio==1.5.8\n",
            "  Downloading nest_asyncio-1.5.8-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: python-dotenv==1.0.0 in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Collecting requests==2.31.0\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting beautifulsoup4==4.12.2\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting tqdm==4.66.1\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting lxml==4.9.3\n",
            "  Downloading lxml-4.9.3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from jax==0.4.13) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax==0.4.13) (3.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Using cached gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.69.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.13.0)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting flaml==2.1.1\n",
            "  Using cached FLAML-2.1.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Using cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "\u001b[31mERROR: Cannot install flaml==2.1.1, jax==0.4.13, jaxlib==0.4.13, numpy==1.24.3, scikit-learn==1.2.2 and tensorflow==2.12.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested numpy==1.24.3\n",
            "    scikit-learn 1.2.2 depends on numpy>=1.17.3\n",
            "    flaml 2.1.1 depends on NumPy>=1.17.0rc1\n",
            "    jax 0.4.13 depends on numpy>=1.21\n",
            "    jaxlib 0.4.13 depends on numpy>=1.21\n",
            "    tensorflow 2.12.0 depends on numpy<1.24 and >=1.22\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3 scikit-learn==1.2.2 flaml==2.1.1 pandas==1.5.3 aiohttp==3.9.5 requests==2.31.0 beautifulsoup4==4.12.3 python-dotenv==1.0.1 openpyxl==3.1.2 tqdm==4.66.2 tenacity==8.2.3 uvicorn==0.29.0 jinja2==3.1.3 httpx==0.26.0 pyautogen==0.1.5 pyyaml==6.0.1 fastapi==0.110.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kcW1Ng9e-Hxk",
        "outputId": "24a0aafd-b6fc-455a-b64b-7af113fd3932"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: flaml==2.1.1 in /usr/local/lib/python3.11/dist-packages (2.1.1)\n",
            "Collecting pandas==1.5.3\n",
            "  Using cached pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting aiohttp==3.9.5\n",
            "  Downloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting requests==2.31.0\n",
            "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting beautifulsoup4==4.12.3\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting python-dotenv==1.0.1\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting openpyxl==3.1.2\n",
            "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting tqdm==4.66.2\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting tenacity==8.2.3\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting uvicorn==0.29.0\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2==3.1.3\n",
            "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting httpx==0.26.0\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting pyautogen==0.1.5\n",
            "  Downloading pyautogen-0.1.5-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pyyaml==6.0.1\n",
            "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting fastapi==0.110.0\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==1.5.3) (2025.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.9.5) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.9.5) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.9.5) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.9.5) (6.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.9.5) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4==4.12.3) (2.6)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl==3.1.2) (2.0.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.29.0) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.29.0) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2==3.1.3) (3.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.26.0) (4.8.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.26.0) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.26.0) (1.3.1)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.1.5) (5.6.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.1.5) (1.59.7)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.1.5) (2.5.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.110.0) (2.6.2)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi==0.110.0)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.110.0) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.110.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.110.0) (2.16.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.17.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.9.5) (0.3.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (0.8.2)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
            "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "Downloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
            "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "Downloading pyautogen-0.1.5-py3-none-any.whl (68 kB)\n",
            "Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "Installing collected packages: uvicorn, tqdm, tenacity, requests, pyyaml, python-dotenv, openpyxl, numpy, jinja2, beautifulsoup4, starlette, pandas, httpx, aiohttp, fastapi, pyautogen\n",
            "  Attempting uninstall: uvicorn\n",
            "    Found existing installation: uvicorn 0.30.3\n",
            "    Uninstalling uvicorn-0.30.3:\n",
            "      Successfully uninstalled uvicorn-0.30.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: python-dotenv\n",
            "    Found existing installation: python-dotenv 1.0.0\n",
            "    Uninstalling python-dotenv-1.0.0:\n",
            "      Successfully uninstalled python-dotenv-1.0.0\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 3.1.5\n",
            "    Uninstalling openpyxl-3.1.5:\n",
            "      Successfully uninstalled openpyxl-3.1.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.5\n",
            "    Uninstalling Jinja2-3.1.5:\n",
            "      Successfully uninstalled Jinja2-3.1.5\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.13.3\n",
            "    Uninstalling beautifulsoup4-4.13.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.13.3\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.37.2\n",
            "    Uninstalling starlette-0.37.2:\n",
            "      Successfully uninstalled starlette-0.37.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.15\n",
            "    Uninstalling aiohttp-3.11.15:\n",
            "      Successfully uninstalled aiohttp-3.11.15\n",
            "  Attempting uninstall: fastapi\n",
            "    Found existing installation: fastapi 0.111.1\n",
            "    Uninstalling fastapi-0.111.1:\n",
            "      Successfully uninstalled fastapi-0.111.1\n",
            "  Attempting uninstall: pyautogen\n",
            "    Found existing installation: pyautogen 0.7.0\n",
            "    Uninstalling pyautogen-0.7.0:\n",
            "      Successfully uninstalled pyautogen-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autogen 0.7.0 requires pyautogen==0.7.0, but you have pyautogen 0.1.5 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.37.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "mizani 0.13.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "xarray 2025.1.2 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 2.6.2 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.0 which is incompatible.\n",
            "langchain 0.3.22 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.6.2 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "dask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-genai 1.9.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.26.0 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.9.5 beautifulsoup4-4.12.3 fastapi-0.110.0 httpx-0.26.0 jinja2-3.1.3 numpy-1.24.3 openpyxl-3.1.2 pandas-1.5.3 pyautogen-0.1.5 python-dotenv-1.0.1 pyyaml-6.0.1 requests-2.31.0 starlette-0.36.3 tenacity-8.2.3 tqdm-4.66.2 uvicorn-0.29.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "aiohttp",
                  "dotenv",
                  "numpy",
                  "requests",
                  "tqdm"
                ]
              },
              "id": "27353e5144e94ce399e2b0188c059d82"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Safely reinstall only key packages WITHOUT restarting runtime\n",
        "!pip install fastapi==0.110.0 uvicorn==0.29.0 python-dotenv==1.0.1 \\\n",
        "    pydantic==2.6.2 pdfminer-six==20231228 pdfplumber==0.11.1 \\\n",
        "    nltk==3.8.1 requests==2.31.0 httpx==0.26.0 tqdm==4.66.2 \\\n",
        "    nest-asyncio==1.6.0 autogen==0.7.0 pyautogen==0.7.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDER3YLV_6eR",
        "outputId": "db849cca-7407-4ba9-fe26-2baced4ffef2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi==0.110.0 in /usr/local/lib/python3.11/dist-packages (0.110.0)\n",
            "Requirement already satisfied: uvicorn==0.29.0 in /usr/local/lib/python3.11/dist-packages (0.29.0)\n",
            "Requirement already satisfied: python-dotenv==1.0.1 in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pydantic==2.6.2 in /usr/local/lib/python3.11/dist-packages (2.6.2)\n",
            "Requirement already satisfied: pdfminer-six==20231228 in /usr/local/lib/python3.11/dist-packages (20231228)\n",
            "Requirement already satisfied: pdfplumber==0.11.1 in /usr/local/lib/python3.11/dist-packages (0.11.1)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.11/dist-packages (3.8.1)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.11/dist-packages (2.31.0)\n",
            "Requirement already satisfied: httpx==0.26.0 in /usr/local/lib/python3.11/dist-packages (0.26.0)\n",
            "Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.11/dist-packages (4.66.2)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: autogen==0.7.0 in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Collecting pyautogen==0.7.0\n",
            "  Using cached pyautogen-0.7.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.110.0) (0.36.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.110.0) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.29.0) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.29.0) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.6.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.6.2) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six==20231228) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer-six==20231228) (44.0.0)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber==0.11.1) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber==0.11.1) (4.30.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk==3.8.1) (2024.11.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0) (2024.12.14)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.26.0) (4.8.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.26.0) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.26.0) (1.3.1)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (0.0.8)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (7.1.0)\n",
            "Requirement already satisfied: fast-depends<3,>=2.4.12 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (2.4.12)\n",
            "Requirement already satisfied: flaml in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (2.1.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (1.24.3)\n",
            "Requirement already satisfied: openai>=1.58 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (1.59.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (24.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (2.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (0.8.0)\n",
            "Requirement already satisfied: websockets<15,>=14 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (14.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer-six==20231228) (1.17.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.0) (0.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six==20231228) (2.22)\n",
            "Using cached pyautogen-0.7.0-py3-none-any.whl (497 kB)\n",
            "Installing collected packages: pyautogen\n",
            "  Attempting uninstall: pyautogen\n",
            "    Found existing installation: pyautogen 0.1.5\n",
            "    Uninstalling pyautogen-0.1.5:\n",
            "      Successfully uninstalled pyautogen-0.1.5\n",
            "Successfully installed pyautogen-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ae.core.skills.extract_keywords import extract_keywords\n",
        "\n",
        "keywords = extract_keywords(resume_text, top_n=10)\n",
        "print(\"Extracted keywords:\", keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "zoY6uBlPFAum",
        "outputId": "a8ada94f-769e-43b9-8112-eb2fe8bba3c2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/tune/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mray_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-5336b109c995>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskills\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_keywords\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracted keywords:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m  \u001b[0;31m# type: ignore # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskills\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautogen_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutogenWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaywright_manager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlaywrightManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/core/agents/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbrowser_nav_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrowserNavAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/core/agents/browser_nav_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mautogen\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_ltm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_user_ltm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0magentchat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcode_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDEFAULT_MODEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFAST_MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexception_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/agentchat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# SPDX-License-Identifier: MIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0massistant_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAssistantAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitiate_chats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m from .contrib.reasoning_agent import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/agentchat/assistant_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntime_logging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog_new_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconversable_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConversableAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/agentchat/conversable_agent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_dump\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m from ..code_utils import (\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mPYTHON_VARIANTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mUNKNOWN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/code_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdocker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUserMessageImageContentPart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserMessageTextContentPart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/oai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpenAIWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompletion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatCompletion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompletion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m from autogen.oai.openai_utils import (\n\u001b[1;32m     11\u001b[0m     \u001b[0mconfig_list_from_dotenv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/autogen/oai/completion.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mflaml_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnull_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBlendSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_formatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlendSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFLOW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlendSearchTuner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monlineml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautovw\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoVW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/automl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoML\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger_formatter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSearchState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoMLState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"AutoML\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AutoMLState\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SearchState\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"logger_formatter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/automl/automl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSearchState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoMLState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/automl/state.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/tune/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     from .sample import (\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0muniform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mquniform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flaml/tune/sample.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Added in numpy>=1.17 but we require numpy>=1.16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mnp_random_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mLEGACY_RNG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mQuick\u001b[0m \u001b[0msanity\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mbugs\u001b[0m \u001b[0mcaused\u001b[0m \u001b[0mby\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mThere\u001b[0m \u001b[0mare\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mBLAS\u001b[0m \u001b[0mABI\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mcause\u001b[0m \u001b[0mwrong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0munder\u001b[0m \u001b[0mspecific\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0mconditions\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnecessarily\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXZ9576tFWQk",
        "outputId": "7465ae75-2308-4f22-96cb-cf1be3a39336"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray) (4.25.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray) (2.31.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->ray) (4.12.2)\n",
            "Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ray\n",
            "Successfully installed ray-2.44.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os; os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "3rh6ZGWvFmP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3 flaml==2.3.3 scikit-learn==1.2.2 ray\n",
        "!pip install playwright pdfplumber nltk fastapi uvicorn requests python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HN3npt5Fxac",
        "outputId": "19044b6f-7e78-4324-9020-2dbf7161dd1c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.11/dist-packages (1.24.3)\n",
            "Collecting flaml==2.3.3\n",
            "  Using cached FLAML-2.3.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: ray in /usr/local/lib/python3.11/dist-packages (2.44.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray) (8.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray) (4.25.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ray) (6.0.1)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray) (2.31.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray) (0.24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema->ray) (4.12.2)\n",
            "Using cached FLAML-2.3.3-py3-none-any.whl (314 kB)\n",
            "Installing collected packages: flaml\n",
            "  Attempting uninstall: flaml\n",
            "    Found existing installation: FLAML 2.1.1\n",
            "    Uninstalling FLAML-2.1.1:\n",
            "      Successfully uninstalled FLAML-2.1.1\n",
            "Successfully installed flaml-2.3.3\n",
            "Requirement already satisfied: playwright in /usr/local/lib/python3.11/dist-packages (1.44.0)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.8.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.110.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.29.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.31.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: greenlet==3.0.3 in /usr/local/lib/python3.11/dist-packages (from playwright) (3.0.3)\n",
            "Requirement already satisfied: pyee==11.1.0 in /usr/local/lib/python3.11/dist-packages (from playwright) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee==11.1.0->playwright) (4.12.2)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (44.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.6.2)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.36.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.16.3)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi) (4.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -e /content/Agent-E-master_xxx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWyJPoFzF511",
        "outputId": "58d70b27-6639-4ccd-c1ca-cf5c4d2ede3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/Agent-E-master_xxx\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ae\n",
            "  Building editable for ae (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ae: filename=ae-0.0.0-0.editable-py3-none-any.whl size=3452 sha256=533d8b2d93e31b7e7995d3709fad7d240b4dc079772031ecc2f364dcca14b08a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z9re4fqb/wheels/71/26/bc/bb13d082963dbb7a39de6965c7dae008800b50235abe566ba8\n",
            "Successfully built ae\n",
            "Installing collected packages: ae\n",
            "Successfully installed ae-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ae.core.skills.extract_keywords import extract_keywords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf6U8GrNGB8A",
        "outputId": "e103a5ed-abc2-4242-c8da-51dc8c16b2f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created log folder at: /content/Agent-E-master_xxx/ae/log_files\n",
            "Created temp folder at: /content/Agent-E-master_xxx/temp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/Agent-E-master_xxx')"
      ],
      "metadata": {
        "id": "dl_NdmYBGINl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the print and return bugs in openai_llm_helper.py\n",
        "!sed -i 's/print response/print(response)/g' /content/Agent-E-master_xxx/ae/utils/openai_llm_helper.py\n",
        "!sed -i 's/return  Response/return response/g' /content/Agent-E-master_xxx/ae/utils/openai_llm_helper.py"
      ],
      "metadata": {
        "id": "9IGssQD8GSGe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔑 Configure API keys and model\n",
        "import os\n",
        "os.environ[\"AUTOGEN_MODEL_API_KEY\"] = \"be5738a9e9msh08bfcd8fad98672p136d4bjsn7df8eb80c816\"  # Replace with your RapidAPI key\n",
        "os.environ[\"AUTOGEN_MODEL_NAME\"] = \"mixtral8x7b\"           # Model name (example)\n",
        "# If using a separate key for job search API (usually not required), also set:\n",
        "# os.environ[\"JOB_API_KEY\"] = \"<YOUR_RAPIDAPI_KEY_FOR_JSEARCH>\""
      ],
      "metadata": {
        "id": "IQI3I841GoiE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "resume_path = \"/content/resume.pdf\"  # TODO: change to your resume file path in Drive\n",
        "with pdfplumber.open(resume_path) as pdf:\n",
        "    resume_text = \"\"\n",
        "    for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            resume_text += text + \"\\n\"\n",
        "\n",
        "resume_text = resume_text.strip()\n",
        "print(\"Resume text length:\", len(resume_text), \"characters\")\n",
        "print(resume_text[:500], \"...\")  # preview first 500 characters\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwQQzbabG0Di",
        "outputId": "2e80ee4e-66ae-4a43-e432-1815d4e2edd3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume text length: 1646 characters\n",
            "Yash Agrawal\n",
            "iiityash@gmail.com | +91 8218469891 | inkedin.com/in/yash-agrawal-18486a145 | India\n",
            "MotivatedIntellectual aspiring tofollow passioninbuilding robustwebappsand DataScience\n",
            "projects, livesinBangalore.\n",
            "EDUCATION: IIIT Gwalior [2017 - 2022]\n",
            "Post Graduation: IntegratedDualDegree (B.Tech + MBA)inIT\n",
            "HackerRank : 10,001(As of2023)\n",
            "EXPERIENCE: IVTREE, Bangalore\n",
            "(Building RobustWeb appsusing RESTAPI) (05/2023- TillDate)\n",
            "PROJECTS: Deep Learning ( DL ) To Predict ElectroCardiGram - Python\n",
            "A mod ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = extract_keywords(resume_text, top_n=10)\n",
        "print(\"Extracted keywords:\", keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "676L7vdIG7Bt",
        "outputId": "f29a6520-4814-4302-b900-b9d1bf0c7993"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted keywords: ['python', 'yash', 'agrawal', 'com', 'projects', 'tech', 'machinelearning', 'systems', 'java', 'iiityash']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Define the job search query (you can use resume keywords or your own criteria)\n",
        "job_query = \"Node.js developer in New York\"  # e.g., \"Data Scientist in San Francisco\"\n",
        "api_url = \"https://jsearch.p.rapidapi.com/search\"\n",
        "query_params = {\"query\": job_query, \"num_pages\": \"1\"}\n",
        "\n",
        "# Use the same RapidAPI key for job search (or JOB_API_KEY if set separately)\n",
        "api_headers = {\n",
        "    \"X-RapidAPI-Key\": os.environ.get(\"JOB_API_KEY\", os.environ.get(\"AUTOGEN_MODEL_API_KEY\")),\n",
        "    \"X-RapidAPI-Host\": \"jsearch.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "response = requests.get(api_url, headers=api_headers, params=query_params)\n",
        "if response.status_code != 200:\n",
        "    raise Exception(f\"Job API request failed: {response.status_code}, {response.text}\")\n",
        "jobs_data = response.json().get(\"data\", [])\n",
        "print(f\"Found {len(jobs_data)} jobs for query: '{job_query}'\")\n",
        "# Print the first 5 job titles and companies\n",
        "for job in jobs_data[:5]:\n",
        "    title = job.get('job_title')\n",
        "    company = job.get('employer_name')\n",
        "    print(f\"- {title} at {company}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArVUCtDXG-un",
        "outputId": "9e9b04f6-7db0-4dbf-9e7c-dc1af0f3b93e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10 jobs for query: 'Node.js developer in New York'\n",
            "- NodeJS Developer (Backend) @ New York City at Sumeru\n",
            "- Lead Full-Stack Engineer (Node.js and Angular) at EPAM Systems\n",
            "- Node Fullstack Developer at Anagh Technologies, Inc.\n",
            "- Node JS Developer at codesbright\n",
            "- Principal Full Stack Node.js Engineer - Can be remote! at ADP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the first job result (you can pick a different index if desired)\n",
        "if not jobs_data:\n",
        "    raise Exception(\"No jobs found for the query – adjust the query or try again.\")\n",
        "job = jobs_data[0]\n",
        "\n",
        "job_title = job.get(\"job_title\")\n",
        "company = job.get(\"employer_name\")\n",
        "job_desc = job.get(\"job_description\", \"\")\n",
        "print(f\"Generating cover letter for: {job_title} at {company}\\n\")\n",
        "\n",
        "# Build a prompt for the LLM\n",
        "prompt = (\n",
        "    \"You are an expert career assistant. Using the applicant's resume and the job description below, \"\n",
        "    \"write a personalized cover letter for the job.\\n\\n\"\n",
        "    f\"**Resume:**\\n{resume_text}\\n\\n\"\n",
        "    f\"**Job Description ({job_title} at {company}):**\\n{job_desc}\\n\\n\"\n",
        "    \"Based on the resume, highlight the candidate's relevant skills and experiences that match the job requirements. \"\n",
        "    \"The cover letter should sound professional and enthusiastic about the opportunity.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v-oNXtxHIjx",
        "outputId": "f95d0754-4993-4da4-e558-932434706f0a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating cover letter for: NodeJS Developer (Backend) @ New York City at Sumeru\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ae.utils.llm_wrapper import query_llm_mixtral\n",
        "\n",
        "cover_letter = query_llm_mixtral(prompt, temperature=0.7, max_tokens=500)\n",
        "print(\"**Generated Cover Letter:**\\n\")\n",
        "print(cover_letter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "NUau9NYuHXod",
        "outputId": "9aa7c438-1c50-4f25-e560-502e781db046"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "RapidAPI LLM request failed: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/utils/llm_wrapper.py\u001b[0m in \u001b[0;36mquery_llm_mixtral\u001b[0;34m(prompt, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-49c130e9be0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_llm_mixtral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcover_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_llm_mixtral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**Generated Cover Letter:**\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_letter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/utils/llm_wrapper.py\u001b[0m in \u001b[0;36mquery_llm_mixtral\u001b[0;34m(prompt, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RapidAPI LLM request failed: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Parse response (handle JSON or plain text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: RapidAPI LLM request failed: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# ✅ Use your valid RapidAPI key\n",
        "os.environ[\"AUTOGEN_MODEL_API_KEY\"] = \"be5738a9e9msh08bfcd8fad98672p136d4bjsn7df8eb80c816\"\n",
        "\n",
        "# ✅ Use the correct base URL for \"Mixtral 8x7B\" endpoint\n",
        "base_url = \"https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/mixtral-8x7b\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"X-RapidAPI-Key\": os.environ[\"AUTOGEN_MODEL_API_KEY\"],\n",
        "    \"X-RapidAPI-Host\": \"llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"prompt\": \"Write a short cover letter for a software engineer job.\",\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 500\n",
        "}\n",
        "\n",
        "response = requests.post(base_url, json=payload, headers=headers)\n",
        "\n",
        "print(f\"Status Code: {response.status_code}\")\n",
        "print(\"Response:\", response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn82lSs0HfRS",
        "outputId": "63a24690-2a02-4371-963c-b8b003c15689"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 404\n",
            "Response: {\"message\":\"Endpoint '\\/mixtral-8x7b' does not exist\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Define the job search query (you can use resume keywords or your own criteria)\n",
        "job_query = \"Node.js developer in New York\"  # e.g., \"Data Scientist in San Francisco\"\n",
        "api_url = \"https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/mixtral-8x7b\"\n",
        "query_params = {\"query\": job_query, \"num_pages\": \"1\"}\n",
        "\n",
        "# Use the same RapidAPI key for job search (or JOB_API_KEY if set separately)\n",
        "api_headers = {\n",
        "    \"X-RapidAPI-Key\": os.environ.get(\"JOB_API_KEY\", os.environ.get(\"AUTOGEN_MODEL_API_KEY\")),\n",
        "    \"X-RapidAPI-Host\": \"llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "response = requests.get(api_url, headers=api_headers, params=query_params)\n",
        "if response.status_code != 200:\n",
        "    raise Exception(f\"Job API request failed: {response.status_code}, {response.text}\")\n",
        "jobs_data = response.json().get(\"data\", [])\n",
        "print(f\"Found {len(jobs_data)} jobs for query: '{job_query}'\")\n",
        "# Print the first 5 job titles and companies\n",
        "for job in jobs_data[:5]:\n",
        "    title = job.get('job_title')\n",
        "    company = job.get('employer_name')\n",
        "    print(f\"- {title} at {company}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BypdjGNhJOfI",
        "outputId": "be9b6623-33f8-41d7-c148-cbc90140cc57"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Job API request failed: 404, {\"message\":\"Endpoint '\\/mixtral-8x7b' does not exist\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-378ea050c782>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Job API request failed: {response.status_code}, {response.text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mjobs_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(jobs_data)} jobs for query: '{job_query}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Job API request failed: 404, {\"message\":\"Endpoint '\\/mixtral-8x7b' does not exist\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ae.utils.llm_wrapper import query_llm_mixtral\n",
        "\n",
        "cover_letter = query_llm_mixtral(prompt, temperature=0.7, max_tokens=500)\n",
        "print(\"**Generated Cover Letter:**\\n\")\n",
        "print(cover_letter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "qvaheR5jKNe5",
        "outputId": "7084fa38-22d0-4ae3-8a69-411e6db05246"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "RapidAPI LLM request failed: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/utils/llm_wrapper.py\u001b[0m in \u001b[0;36mquery_llm_mixtral\u001b[0;34m(prompt, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-49c130e9be0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_llm_mixtral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcover_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_llm_mixtral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**Generated Cover Letter:**\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_letter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/utils/llm_wrapper.py\u001b[0m in \u001b[0;36mquery_llm_mixtral\u001b[0;34m(prompt, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RapidAPI LLM request failed: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Parse response (handle JSON or plain text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: RapidAPI LLM request failed: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# ✅ Use your valid RapidAPI key\n",
        "os.environ[\"AUTOGEN_MODEL_API_KEY\"] = \"be5738a9e9msh08bfcd8fad98672p136d4bjsn7df8eb80c816\"\n",
        "\n",
        "# ✅ Use the correct base URL for \"Mixtral 8x7B\" endpoint\n",
        "base_url = \"https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/mixtral-8x7b\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"X-RapidAPI-Key\": os.environ[\"AUTOGEN_MODEL_API_KEY\"],\n",
        "    \"X-RapidAPI-Host\": \"llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"prompt\": \"Write a short cover letter for a software engineer job.\",\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 500\n",
        "}\n",
        "\n",
        "response = requests.post(base_url, json=payload, headers=headers)\n",
        "\n",
        "print(f\"Status Code: {response.status_code}\")\n",
        "print(\"Response:\", response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZQKkkj4KW5L",
        "outputId": "1ba8d68b-332b-4138-b602-89e1afa3ea4a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 404\n",
            "Response: {\"message\":\"Endpoint '\\/mixtral-8x7b' does not exist\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ae.utils.llm_wrapper import query_llm_mixtral\n",
        "\n",
        "cover_letter = query_llm_mixtral(prompt, temperature=0.7, max_tokens=500)\n",
        "print(\"**Generated Cover Letter:**\\n\")\n",
        "print(cover_letter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "FVVR5BFrKkBZ",
        "outputId": "12e123ba-a88d-40da-c487-9ba67e3fb07e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "RapidAPI LLM request failed: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/utils/llm_wrapper.py\u001b[0m in \u001b[0;36mquery_llm_mixtral\u001b[0;34m(prompt, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-49c130e9be0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_llm_mixtral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcover_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_llm_mixtral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**Generated Cover Letter:**\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_letter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/utils/llm_wrapper.py\u001b[0m in \u001b[0;36mquery_llm_mixtral\u001b[0;34m(prompt, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RapidAPI LLM request failed: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Parse response (handle JSON or plain text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: RapidAPI LLM request failed: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the first job result (you can pick a different index if desired)\n",
        "if not jobs_data:\n",
        "    raise Exception(\"No jobs found for the query – adjust the query or try again.\")\n",
        "job = jobs_data[0]\n",
        "\n",
        "job_title = job.get(\"job_title\")\n",
        "company = job.get(\"employer_name\")\n",
        "job_desc = job.get(\"job_description\", \"\")\n",
        "print(f\"Generating cover letter for: {job_title} at {company}\\n\")\n",
        "\n",
        "# Build a prompt for the LLM\n",
        "prompt = (\n",
        "    \"You are an expert career assistant. Using the applicant's resume and the job description below, \"\n",
        "    \"write a personalized cover letter for the job.\\n\\n\"\n",
        "    f\"**Resume:**\\n{resume_text}\\n\\n\"\n",
        "    f\"**Job Description ({job_title} at {company}):**\\n{job_desc}\\n\\n\"\n",
        "    \"Based on the resume, highlight the candidate's relevant skills and experiences that match the job requirements. \"\n",
        "    \"The cover letter should sound professional and enthusiastic about the opportunity.\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTJ3HXKyKmko",
        "outputId": "b3828a27-731c-4966-9d04-a32210e9741b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating cover letter for: NodeJS Developer (Backend) @ New York City at Sumeru\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jobs_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9b-zflTK1FW",
        "outputId": "335d826d-f908-4893-a0fc-cdc311798156"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'job_id': '8bfQmtvlKXPhEL7iAAAAAA==',\n",
              "  'job_title': 'NodeJS Developer (Backend) @ New York City',\n",
              "  'employer_name': 'Sumeru',\n",
              "  'employer_logo': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRsyjenXa37sZlcGnc14BndGfo0KvJExkBiC_RQ&s=0',\n",
              "  'employer_website': 'https://www.sumeru.us',\n",
              "  'job_publisher': 'Dice',\n",
              "  'job_employment_type': 'Contractor',\n",
              "  'job_employment_types': ['CONTRACTOR', 'CONTRACTOR'],\n",
              "  'job_apply_link': 'https://www.dice.com/job-detail/ca48e5a3-c059-4813-bcd1-c7c14d842823?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': True,\n",
              "  'apply_options': [{'publisher': 'Dice',\n",
              "    'apply_link': 'https://www.dice.com/job-detail/ca48e5a3-c059-4813-bcd1-c7c14d842823?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': True}],\n",
              "  'job_description': 'Role: Backend Engineer\\n\\nLocation: NYC, NY - 10006,(hybrid 2-3 days in a week is must.)\\nSkills required: Node.JS, Javascript, AWS and CICD Experience Required: 10+ Years Key responsibilities:\\n• Develop and maintain server-side applications using Node.js in a cloud-native environment.\\n• Design and implement microservices architecture for scalable and resilient applications.\\n• Leverage AWS services such as Lambda, Fargate, S3, RDS, Step Functions, and API Gateway to build and deploy applications.\\n• Collaborate with front-end developers to integrate user-facing elements with server-side logic.\\n• Optimize applications for maximum speed and scalability.\\n• Implement and maintain CI/CD pipelines for automated testing and deployment.\\n• Monitor and troubleshoot application performance and resolve issues as they arise.\\n• Ensure code quality through code reviews, unit testing, and adherence to best practices.\\n• Stay updated with emerging technologies and industry trends to continuously improve development processes.',\n",
              "  'job_is_remote': False,\n",
              "  'job_posted_at': '23 days ago',\n",
              "  'job_posted_at_timestamp': 1741910400,\n",
              "  'job_posted_at_datetime_utc': '2025-03-14T00:00:00.000Z',\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': None,\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D8bfQmtvlKXPhEL7iAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_salary': None,\n",
              "  'job_min_salary': None,\n",
              "  'job_max_salary': None,\n",
              "  'job_salary_period': None,\n",
              "  'job_highlights': {'Qualifications': ['Skills required: Node.JS, Javascript, AWS and CICD Experience Required: 10+ Years Key responsibilities:',\n",
              "    'Develop and maintain server-side applications using Node.js in a cloud-native environment',\n",
              "    'Design and implement microservices architecture for scalable and resilient applications',\n",
              "    'Leverage AWS services such as Lambda, Fargate, S3, RDS, Step Functions, and API Gateway to build and deploy applications',\n",
              "    'Collaborate with front-end developers to integrate user-facing elements with server-side logic',\n",
              "    'Optimize applications for maximum speed and scalability',\n",
              "    'Stay updated with emerging technologies and industry trends to continuously improve development processes'],\n",
              "   'Responsibilities': ['Location: NYC, NY - 10006,(hybrid 2-3 days in a week is must.)',\n",
              "    'Implement and maintain CI/CD pipelines for automated testing and deployment',\n",
              "    'Monitor and troubleshoot application performance and resolve issues as they arise',\n",
              "    'Ensure code quality through code reviews, unit testing, and adherence to best practices']},\n",
              "  'job_onet_soc': '15113400',\n",
              "  'job_onet_job_zone': '3'},\n",
              " {'job_id': 'acXfcRl1abspILpDAAAAAA==',\n",
              "  'job_title': 'Lead Full-Stack Engineer (Node.js and Angular)',\n",
              "  'employer_name': 'EPAM Systems',\n",
              "  'employer_logo': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTqUHzGBeR7SSZj3b1iSLlswALaKNCrcrs3ESgd&s=0',\n",
              "  'employer_website': None,\n",
              "  'job_publisher': 'The Muse',\n",
              "  'job_employment_type': 'Full-time',\n",
              "  'job_employment_types': ['FULLTIME'],\n",
              "  'job_apply_link': 'https://www.themuse.com/jobs/epamsystems/lead-fullstack-engineer-nodejs-and-angular-d89efa?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': True,\n",
              "  'apply_options': [{'publisher': 'The Muse',\n",
              "    'apply_link': 'https://www.themuse.com/jobs/epamsystems/lead-fullstack-engineer-nodejs-and-angular-d89efa?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': True},\n",
              "   {'publisher': 'Adzuna',\n",
              "    'apply_link': 'https://www.adzuna.com/details/5131138683?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False}],\n",
              "  'job_description': \"We are actively seeking a proficient Full-Stack Developer knowledgeable in Angular and Node.js. This role requires someone who can integrate seamlessly into our dynamic team and contribute to our ongoing projects effectively.\\nReq.#732535003\\n\\n#LI-DNI#LI-KS4\\n\\nResponsibilities\\n• Design and develop robust front-end applications as well as Microservices using REST APIs, ensuring responsive and efficient user experiences\\n• Lead full-stack development initiatives, demonstrating hands-on technical leadership within the project team\\n• Analyze existing legacy systems and strategize optimal future state architectures and solutions\\n• Foster an agile development environment, continuously iterating and improving product features and processes\\n• Engage with diverse teams across our organization, collaborating effectively with Database divisions, CTO organization, and the API Economy team\\nRequirements\\n• Bachelor's Degree in Computer Science or a similar field; a Master's degree in Computer Science is preferred\\n• At least 5 years of relevant professional experience in full-stack development\\n• Expertise in front-end technologies including Angular and TypeScript and backend integration using Node.js\\n• Proficient with AWS cloud services such as EC2, S3, Lambda, and DynamoDB amongst others\\n• Knowledge of database management systems like DynamoDB, PostgreSQL (optional), and DB2 (legacy)\\n• Experience with Splunk for monitoring and Cucumber for API testing tools\\n• Excellent communication skills, capable of leading client-facing discussions and internal team collaborations\\n• Strong problem-solving abilities, adept at managing ambiguities and driving clarity in complex scenarios\\n• Proven track record of effective team leadership and meticulous attention to detail\\n• Exceptional analytical skills with an ability to foresee and circumnavigate potential challenges in software environments\\n• Demonstrated resilience and adaptability within dynamic and challenging environments\\n• A robust portfolio of successful full-stack development projects\\nWe offer\\n• Medical, Dental and Vision Insurance (Subsidized)\\n• Health Savings Account\\n• Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)\\n• Short-Term and Long-Term Disability (Company Provided)\\n• Life and AD&D Insurance (Company Provided)\\n• Employee Assistance Program\\n• Unlimited access to LinkedIn learning solutions\\n• Matched 401(k) Retirement Savings Plan\\n• Paid Time Off - the employee will be eligible to accrue 15-25 paid days, depending on specific level and tenure with EPAM (accrual eligibility may change over time)\\n• Paid Holidays - nine (9) total per year\\n• Legal Plan and Identity Theft Protection\\n• Accident Insurance\\n• Employee Discounts\\n• Pet Insurance\\n• Employee Stock Purchase Program\\n• If otherwise eligible, participation in the discretionary annual bonus program\\n• If otherwise eligible and hired into a qualifying level, participation in the discretionary Long-Term Incentive (LTI) Program\\nFor remote work in New York City only.\\nEPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.\\n\\nYouTube video player\\nThis posting includes a good faith range of the salary EPAM would reasonably expect to pay the selected candidate. The range provided reflects base salary only. Individual compensation offers within the range are based on a variety of factors, including, but not limited to: geographic location, experience, credentials, education, training; the demand for the role; and overall business and labor market considerations. Most candidates are hired at a salary within the range disclosed. Salary range: $95,000 - $170,000. In addition, the details highlighted in this job posting above are a general description of all other expected benefits and compensation for the position.\\nApplications will be accepted on a rolling basis.\\nIt is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.\",\n",
              "  'job_is_remote': False,\n",
              "  'job_posted_at': '1 day ago',\n",
              "  'job_posted_at_timestamp': 1743811200,\n",
              "  'job_posted_at_datetime_utc': '2025-04-05T00:00:00.000Z',\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': ['dental_coverage', 'paid_time_off', 'health_insurance'],\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DacXfcRl1abspILpDAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_salary': None,\n",
              "  'job_min_salary': None,\n",
              "  'job_max_salary': None,\n",
              "  'job_salary_period': None,\n",
              "  'job_highlights': {'Qualifications': ['We are actively seeking a proficient Full-Stack Developer knowledgeable in Angular and Node.js',\n",
              "    'This role requires someone who can integrate seamlessly into our dynamic team and contribute to our ongoing projects effectively',\n",
              "    'At least 5 years of relevant professional experience in full-stack development',\n",
              "    'Expertise in front-end technologies including Angular and TypeScript and backend integration using Node.js',\n",
              "    'Proficient with AWS cloud services such as EC2, S3, Lambda, and DynamoDB amongst others',\n",
              "    'Knowledge of database management systems like DynamoDB, PostgreSQL (optional), and DB2 (legacy)',\n",
              "    'Experience with Splunk for monitoring and Cucumber for API testing tools',\n",
              "    'Excellent communication skills, capable of leading client-facing discussions and internal team collaborations',\n",
              "    'Strong problem-solving abilities, adept at managing ambiguities and driving clarity in complex scenarios',\n",
              "    'Proven track record of effective team leadership and meticulous attention to detail',\n",
              "    'Exceptional analytical skills with an ability to foresee and circumnavigate potential challenges in software environments',\n",
              "    'Demonstrated resilience and adaptability within dynamic and challenging environments',\n",
              "    'A robust portfolio of successful full-stack development projects'],\n",
              "   'Benefits': ['We offer',\n",
              "    'Medical, Dental and Vision Insurance (Subsidized)',\n",
              "    'Health Savings Account',\n",
              "    'Flexible Spending Accounts (Healthcare, Dependent Care, Commuter)',\n",
              "    'Short-Term and Long-Term Disability (Company Provided)',\n",
              "    'Life and AD&D Insurance (Company Provided)',\n",
              "    'Employee Assistance Program',\n",
              "    'Unlimited access to LinkedIn learning solutions',\n",
              "    'Matched 401(k) Retirement Savings Plan',\n",
              "    'Paid Time Off - the employee will be eligible to accrue 15-25 paid days, depending on specific level and tenure with EPAM (accrual eligibility may change over time)',\n",
              "    'Paid Holidays - nine (9) total per year',\n",
              "    'Legal Plan and Identity Theft Protection',\n",
              "    'Accident Insurance',\n",
              "    'Employee Discounts',\n",
              "    'Pet Insurance',\n",
              "    'Employee Stock Purchase Program',\n",
              "    'If otherwise eligible, participation in the discretionary annual bonus program',\n",
              "    'If otherwise eligible and hired into a qualifying level, participation in the discretionary Long-Term Incentive (LTI) Program',\n",
              "    'This posting includes a good faith range of the salary EPAM would reasonably expect to pay the selected candidate',\n",
              "    'The range provided reflects base salary only',\n",
              "    'Individual compensation offers within the range are based on a variety of factors, including, but not limited to: geographic location, experience, credentials, education, training; the demand for the role; and overall business and labor market considerations',\n",
              "    'Most candidates are hired at a salary within the range disclosed',\n",
              "    'Salary range: $95,000 - $170,000',\n",
              "    'In addition, the details highlighted in this job posting above are a general description of all other expected benefits and compensation for the position'],\n",
              "   'Responsibilities': ['Design and develop robust front-end applications as well as Microservices using REST APIs, ensuring responsive and efficient user experiences',\n",
              "    'Lead full-stack development initiatives, demonstrating hands-on technical leadership within the project team',\n",
              "    'Analyze existing legacy systems and strategize optimal future state architectures and solutions',\n",
              "    'Foster an agile development environment, continuously iterating and improving product features and processes',\n",
              "    'Engage with diverse teams across our organization, collaborating effectively with Database divisions, CTO organization, and the API Economy team']},\n",
              "  'job_onet_soc': '15113400',\n",
              "  'job_onet_job_zone': '3'},\n",
              " {'job_id': 'uUbS-DFoGzUVklDXAAAAAA==',\n",
              "  'job_title': 'Node Fullstack Developer',\n",
              "  'employer_name': 'Anagh Technologies, Inc.',\n",
              "  'employer_logo': None,\n",
              "  'employer_website': None,\n",
              "  'job_publisher': 'ZipRecruiter',\n",
              "  'job_employment_type': 'Contractor',\n",
              "  'job_employment_types': ['CONTRACTOR', 'CONTRACTOR'],\n",
              "  'job_apply_link': 'https://www.ziprecruiter.com/c/Anagh-Technologies,-Inc./Job/Node-Fullstack-Developer/-in-New-York,NY?jid=744fd803a27062b2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': False,\n",
              "  'apply_options': [{'publisher': 'ZipRecruiter',\n",
              "    'apply_link': 'https://www.ziprecruiter.com/c/Anagh-Technologies,-Inc./Job/Node-Fullstack-Developer/-in-New-York,NY?jid=744fd803a27062b2&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False}],\n",
              "  'job_description': 'Full Stack Developer Node with Python or Ruby\\n\\nLong Term\\n\\nNYC, NY - Remote\\n\\nKey Qualifications\\n• At least 5 years of experience, preferably working as part of a team\\n• Deep knowledge of Typescript, JavaScript (Node), Python, or Ruby\\n• Deep knowledge of relational database systems like PostgreSQL or MySQL\\n• Proven track record of designing, building, delivering, and maintaining critical web-based software\\n• You love working in a fast-paced and dynamic environment\\n• Extremely organized, detail-oriented, and thorough in every undertaking\\n• Excellent verbal and written communication skills\\n\\nBonus Qualifications\\n• Experience with massive parallel processors like Spark\\n• Experience with GraphQL\\n• Experience with Airflow',\n",
              "  'job_is_remote': False,\n",
              "  'job_posted_at': None,\n",
              "  'job_posted_at_timestamp': None,\n",
              "  'job_posted_at_datetime_utc': None,\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': None,\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DuUbS-DFoGzUVklDXAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_salary': None,\n",
              "  'job_min_salary': None,\n",
              "  'job_max_salary': None,\n",
              "  'job_salary_period': None,\n",
              "  'job_highlights': {'Qualifications': ['Full Stack Developer Node with Python or Ruby',\n",
              "    'At least 5 years of experience, preferably working as part of a team',\n",
              "    'Deep knowledge of Typescript, JavaScript (Node), Python, or Ruby',\n",
              "    'Deep knowledge of relational database systems like PostgreSQL or MySQL',\n",
              "    'Proven track record of designing, building, delivering, and maintaining critical web-based software',\n",
              "    'You love working in a fast-paced and dynamic environment',\n",
              "    'Extremely organized, detail-oriented, and thorough in every undertaking',\n",
              "    'Excellent verbal and written communication skills',\n",
              "    'Experience with massive parallel processors like Spark',\n",
              "    'Experience with GraphQL',\n",
              "    'Experience with Airflow']},\n",
              "  'job_onet_soc': '15113300',\n",
              "  'job_onet_job_zone': '4'},\n",
              " {'job_id': '7zcq0zPwZj2Jj0tIAAAAAA==',\n",
              "  'job_title': 'Node JS Developer',\n",
              "  'employer_name': 'codesbright',\n",
              "  'employer_logo': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTPd-hps7yHu6ZmQPwa8QzKacpqKLbzwCNNoBVY&s=0',\n",
              "  'employer_website': 'https://www.codesbright.com',\n",
              "  'job_publisher': 'OPTnation',\n",
              "  'job_employment_type': 'Full-time, Part-time, and Contractor',\n",
              "  'job_employment_types': ['FULLTIME', 'PARTTIME', 'CONTRACTOR', 'CONTRACTOR'],\n",
              "  'job_apply_link': 'https://www.optnation.com/node-js-developer-job-in-new-york-ny-view-jobid-33847?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': False,\n",
              "  'apply_options': [{'publisher': 'OPTnation',\n",
              "    'apply_link': 'https://www.optnation.com/node-js-developer-job-in-new-york-ny-view-jobid-33847?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Ladders',\n",
              "    'apply_link': 'https://www.theladders.com/job/node-js-developer-technogeninternationalcompany-new-york-ny_78099147?ir=1&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Jooble',\n",
              "    'apply_link': 'https://jooble.org/jdp/4397620466852152748?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'BeBee',\n",
              "    'apply_link': 'https://us.bebee.com/job/0d64801449692471d70d2588d9081e73?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Www.csharp.com',\n",
              "    'apply_link': 'https://www.csharp.com/jobs/node-js-developer4?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Vaia – Talents',\n",
              "    'apply_link': 'https://talents.vaia.com/companies/technogen-international-company/node-js-developer-5742888/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'GrabJobs',\n",
              "    'apply_link': 'https://grabjobs.co/us/job/full-time/others/fullstack-developer-node-js-138908186?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Recruiter Jobs',\n",
              "    'apply_link': 'https://jobs.recruiter.com/jobs/18719120697-node-js-developer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False}],\n",
              "  'job_description': 'Responsibilities Attend Daily Standup Calls & Offshore Co-ordination if required. Deliver components as committed and raise risk if any road blockers. Get prioritize user stories/Defect & interact with business for clarifications suggestions. Prepare Technical Design for stories and solutioning document for changes/enhancements. Build and deploy application code using the continuous integration system Jenkins. Provide recommendations on best practices within RMS and DB related.\\n\\nKey Skills Valuable Experience. Database Management. Managing Errors. Time Management. Efficient Readable and Compliant Code. Understanding of API Communications',\n",
              "  'job_is_remote': False,\n",
              "  'job_posted_at': None,\n",
              "  'job_posted_at_timestamp': None,\n",
              "  'job_posted_at_datetime_utc': None,\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': None,\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D7zcq0zPwZj2Jj0tIAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_min_salary': 25000,\n",
              "  'job_max_salary': 35000,\n",
              "  'job_salary_period': 'YEAR',\n",
              "  'job_highlights': {'Qualifications': ['Key Skills Valuable Experience',\n",
              "    'Database Management',\n",
              "    'Efficient Readable and Compliant Code'],\n",
              "   'Responsibilities': ['Responsibilities Attend Daily Standup Calls & Offshore Co-ordination if required',\n",
              "    'Deliver components as committed and raise risk if any road blockers',\n",
              "    'Get prioritize user stories/Defect & interact with business for clarifications suggestions',\n",
              "    'Prepare Technical Design for stories and solutioning document for changes/enhancements',\n",
              "    'Build and deploy application code using the continuous integration system Jenkins',\n",
              "    'Provide recommendations on best practices within RMS and DB related',\n",
              "    'Managing Errors',\n",
              "    'Time Management']},\n",
              "  'job_onet_soc': '15113400',\n",
              "  'job_onet_job_zone': '3'},\n",
              " {'job_id': 'TT4NX_QTV5r8oVPAAAAAAA==',\n",
              "  'job_title': 'Principal Full Stack Node.js Engineer - Can be remote!',\n",
              "  'employer_name': 'ADP',\n",
              "  'employer_logo': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSEKMbtTfs9zz1_ToTPZfbtnJFsItA_Ga5nQ_qN&s=0',\n",
              "  'employer_website': None,\n",
              "  'job_publisher': 'ADP Careers',\n",
              "  'job_employment_type': 'Full-time',\n",
              "  'job_employment_types': ['FULLTIME'],\n",
              "  'job_apply_link': 'https://jobs.adp.com/en/jobs/258568/principal-full-stack-nodejs-engineer-can-be-remote/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': False,\n",
              "  'apply_options': [{'publisher': 'ADP Careers',\n",
              "    'apply_link': 'https://jobs.adp.com/en/jobs/258568/principal-full-stack-nodejs-engineer-can-be-remote/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Upwork',\n",
              "    'apply_link': 'https://www.upwork.com/freelance-jobs/apply/Full-Stack-Engineer-Python-JavaScript-Tracking-Attribution_~021902349941723763099/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': True},\n",
              "   {'publisher': 'Workday',\n",
              "    'apply_link': 'https://target.wd5.myworkdayjobs.com/en-US/targetcareers/job/7000-Target-Pkwy-NNCD-0375-Brooklyn-ParkMN-55445/Sr-Engineer---Apply-for-Circle-Card_R0000381846-1/apply/autofillWithResume?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Indeed',\n",
              "    'apply_link': 'https://www.indeed.com/viewjob?jk=6cbfc14bee9b0718&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': True},\n",
              "   {'publisher': 'Built In Seattle',\n",
              "    'apply_link': 'https://www.builtinseattle.com/job/full-stack-engineer-ii-creator-engagement/3982363?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Wellfound',\n",
              "    'apply_link': 'https://wellfound.com/jobs/3252864-backend-full-stack-engineer-api-features?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': True},\n",
              "   {'publisher': 'Built In Colorado',\n",
              "    'apply_link': 'https://www.builtincolorado.com/job/full-stack-engineer-swe-ii-guide-pc/4000692?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Built In San Francisco',\n",
              "    'apply_link': 'https://www.builtinsf.com/job/full-stack-engineer-swe-ii-guide-pc/4000692?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False}],\n",
              "  'job_description': \"Sora, an ADP company, is hiring a Principal Full-Stack Software Engineer\\n\\nThis role is remote anywhere in the United States\\n\\nAccepting applications until 3/31/2025\\n• Do you enjoy working on collaborative and agile teams designing technical solutions to new problems?\\n• Are you empathetic to client needs and inspired by transformation and impacting the lives of millions of people every day?\\n• Are you looking to join a dynamic, inclusive team environment with a culture of belonging?\\n\\nWell, this may be the role for you. Ready to build what’s next?\\n\\nSora, an HR Workflow automation product, is empowering people-focused teams to create exceptional employee experiences. HR teams should be spending time with people, but unfortunately all facets of People teams are bogged down by managing processes instead of helping people. That’s where Sora comes in: we’re building a product that streamlines the tedious and repetitive work People teams do every day, from sending emails to assigning onboarding tasks to a new hire’s manager to syncing data across anywhere from 3 to 20 tools in a customer’s HR stack.\\n\\nAs a Principal Full-Stack Software Engineer, you'll be an integral part of the agile and dynamic Sora engineering team. We take a startup mindset—focused, action-oriented, and quick to execute, while always being thoughtful in our approach.\\n\\nIn this role, you'll collaborate with a diverse group of stakeholders, including Product Managers, Architects, DevOps Engineers, QA Engineers, and our Customer Success team. Together, you'll plan, design, develop, test, and deploy impactful solutions that cater to businesses of all sizes—from small teams to large enterprises. You’ll also engage closely with cross-functional teams across ADP, contributing throughout the entire software development lifecycle (SDLC)—from product alignment and technical discovery to end-to-end integration and ongoing support. Success in this role requires strong collaboration, excellent communication, and deep technical expertise.\\n\\nTo thrive in this role, you’ll need 12+ years of experience in modern web development and cloud technologies, and substantial experience in DevOps (CI/CD pipelines, cloud infrastructure, production support). You’ll lead initiatives to build services and infrastructure for our system, improve performance, scale, and the –ilities (reliability, observability, etc), and contribute to the foundation of our engineering team. You’ll help us keep our code up-to-date with best practices, and be a champion for shipping well-tested and well-organized code. You’ll be a driver for positive change to Sora’s engineering culture, processes and technology.\\n\\nAs part of our team, you’ll find exciting challenges, get opportunities to grow your career, and develop solid friendships as we design what’s next for Sora, ADP, and the industry.\\n\\nLike what you see? Apply now!\\n\\nLearn more about ADP at jobs.adp.com\\n\\nWHAT YOU’LL DO:\\n\\nHere’s what you can expect on a typical day:\\n• Agile. No two days are the same! You’ll design, develop, and test code. You’re perform code reviews for your teammates. Some days you’ll participate in stand-ups and every two weeks you’ll have sprint planning meetings. You’ll also get to interact with our customer success and sales teams to hear directly from clients and prospects.\\n• Build Products. You will use your technical expertise to review your team’s work and help your people excel in an Agile environment. You’re proactive and hands-on. When you see a potential issue, you never leave things hanging and unfinished. When you and your team deliver a finished product, it’s as polished as you could make it.\\n\\nTO SUCCEED IN THIS ROLE:\\n• You’ll have a Bachelor’s degree OR equivalent.\\n• 12+ years of professional experience in relevant skills (in the tech stack below) gained and developed in the same or similar role.\\n• NodeJS\\n• React (or similar modern front-end framework)\\n• Postgres\\n• AWS (EC2, SQS, SES) or similar cloud experience\\n\\nNOTE: Experience in all of these areas is not strictly required. However, we expect Principal engineers to have significant experience in a majority of the stack and to onboard quickly, ramping up to Principal level proficiency on our technologies and tools within a few months.\\n• Substantial (8+ years) of DevOps, infrastructure, and CI/CD experience, including security, performance and scale.\\n• Substantial (8+ years) experience scaling distributed systems, database architecture, observability, security/vulnerability reduction, message queuing.\\n• Significant experience writing technical plans/proposals, completing Proofs of Concept, making and defending recommendations on technical direction/strategy, and leading multiple simultaneous technical projects across multiple scrum teams and/or departments.\\n• Demonstrated success as a cross-functional collaborator and problem solver, working closely with multiple teams throughout an organization.\\n• 8+ years experience as a technical leader and mentor to new or more junior developers.\\n\\nYOU'LL LOVE WORKING HERE BECAUSE YOU CAN:\\n• Have courageous team collaboration. Courage comes from how associates are willing to have difficult conversations, speak up, be an owner, and challenge one another's ideas to find the best solution.\\n• Deliver at epic scale. We deliver real user outcomes using strong judgment and good instincts. We're obsessed with the art of achieving simplicity with a focus on client happiness and productivity.\\n• Be surrounded by curious learners. We align ourselves with other smart people in an environment where we grow and elevate one another to the next level. We encourage our associates to listen, stay agile, and learn from mistakes.\\n• Act like an owner & doer. Mission-driven and committed to leading change, you will be encouraged to take on any challenge and solve complex problems. No tasks are beneath or too great for us. We are hands-on and willing to master our craft.\\n• Give back to others. Always do the right thing for our clients and our community and humbly give back to the community where we live and work. Support our associates in times of need through ADP's Philanthropic Foundation.\\n• Join a company committed to equality and equity. Our goal is to impact lasting change through our actions.\\n\\nWhat are you waiting for? Apply today!\\n\\nFind out why people come to ADP and why they stay: https://youtu.be/ODb8lxBrxrY\\n\\n(ADA version: https://youtu.be/IQjUCA8SOoA )\\n\\n#LI-CZ1\\n\\n#LI-Remote\\n\\nBase salary offers for this position may vary based on factors such as location, skills, and relevant experience. Some positions may include additional compensation in the form of bonus, equity or commissions. We offer the following benefits: Medical, Dental, Vision, Life Insurance, Matched Retirement Savings, Wellness Program, Short-and Long-Term Disability, Charitable Contribution Match, Holidays, Personal Days & Vacation, Paid Volunteer Time Off, and more. The compensation for this role is $102,100.00 - $273,150.00 / Year\\n\\nA little about ADP: We are a comprehensive global provider of cloud-based human capital management (HCM) solutions that unite HR, payroll, talent, time, tax and benefits administration and a leader in business outsourcing services, analytics, and compliance expertise. We believe our people make all the difference in cultivating a down-to-earth culture that embraces our core values, welcomes ideas, encourages innovation, and values belonging. We've received recognition for our work by many esteemed organizations, learn more at ADP Awards and Recognition.\\n\\nDiversity, Equity, Inclusion & Equal Employment Opportunity at ADP: ADP is committed to an inclusive, diverse and equitable workplace, and is further committed to providing equal employment opportunities regardless of any protected characteristic including: race, color, genetic information, creed, national origin, religion, sex, affectional or sexual orientation, gender identity or expression, lawful alien status, ancestry, age, marital status, protected veteran status or disability. Hiring decisions are based upon ADP’s operating needs, and applicant merit including, but not limited to, qualifications, experience, ability, availability, cooperation, and job performance.\\n\\nEthics at ADP: ADP has a long, proud history of conducting business with the highest ethical standards and full compliance with all applicable laws. We also expect our people to uphold our values with the highest level of integrity and behave in a manner that fosters an honest and respectful workplace. Click https://jobs.adp.com/life-at-adp/ to learn more about ADP’s culture and our full set of values.\",\n",
              "  'job_is_remote': True,\n",
              "  'job_posted_at': None,\n",
              "  'job_posted_at_timestamp': None,\n",
              "  'job_posted_at_datetime_utc': None,\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': ['dental_coverage', 'paid_time_off', 'health_insurance'],\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DTT4NX_QTV5r8oVPAAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_salary': None,\n",
              "  'job_min_salary': None,\n",
              "  'job_max_salary': None,\n",
              "  'job_salary_period': None,\n",
              "  'job_highlights': {'Qualifications': ['Do you enjoy working on collaborative and agile teams designing technical solutions to new problems?',\n",
              "    'To thrive in this role, you’ll need 12+ years of experience in modern web development and cloud technologies, and substantial experience in DevOps (CI/CD pipelines, cloud infrastructure, production support)',\n",
              "    'No two days are the same!',\n",
              "    'You’re proactive and hands-on',\n",
              "    'When you see a potential issue, you never leave things hanging and unfinished',\n",
              "    'You’ll have a Bachelor’s degree OR equivalent',\n",
              "    '12+ years of professional experience in relevant skills (in the tech stack below) gained and developed in the same or similar role',\n",
              "    'NodeJS',\n",
              "    'React (or similar modern front-end framework)',\n",
              "    'Postgres',\n",
              "    'AWS (EC2, SQS, SES) or similar cloud experience',\n",
              "    'NOTE: Experience in all of these areas is not strictly required',\n",
              "    'However, we expect Principal engineers to have significant experience in a majority of the stack and to onboard quickly, ramping up to Principal level proficiency on our technologies and tools within a few months',\n",
              "    'Substantial (8+ years) of DevOps, infrastructure, and CI/CD experience, including security, performance and scale',\n",
              "    'Substantial (8+ years) experience scaling distributed systems, database architecture, observability, security/vulnerability reduction, message queuing',\n",
              "    'Significant experience writing technical plans/proposals, completing Proofs of Concept, making and defending recommendations on technical direction/strategy, and leading multiple simultaneous technical projects across multiple scrum teams and/or departments',\n",
              "    'Demonstrated success as a cross-functional collaborator and problem solver, working closely with multiple teams throughout an organization',\n",
              "    '8+ years experience as a technical leader and mentor to new or more junior developers',\n",
              "    \"Courage comes from how associates are willing to have difficult conversations, speak up, be an owner, and challenge one another's ideas to find the best solution\",\n",
              "    \"We're obsessed with the art of achieving simplicity with a focus on client happiness and productivity\",\n",
              "    'Be surrounded by curious learners'],\n",
              "   'Benefits': ['Have courageous team collaboration',\n",
              "    'Give back to others',\n",
              "    'Always do the right thing for our clients and our community and humbly give back to the community where we live and work',\n",
              "    'Some positions may include additional compensation in the form of bonus, equity or commissions',\n",
              "    'We offer the following benefits: Medical, Dental, Vision, Life Insurance, Matched Retirement Savings, Wellness Program, Short-and Long-Term Disability, Charitable Contribution Match, Holidays, Personal Days & Vacation, Paid Volunteer Time Off, and more',\n",
              "    'The compensation for this role is $102,100.00 - $273,150.00 / Year'],\n",
              "   'Responsibilities': [\"As a Principal Full-Stack Software Engineer, you'll be an integral part of the agile and dynamic Sora engineering team\",\n",
              "    \"In this role, you'll collaborate with a diverse group of stakeholders, including Product Managers, Architects, DevOps Engineers, QA Engineers, and our Customer Success team\",\n",
              "    \"Together, you'll plan, design, develop, test, and deploy impactful solutions that cater to businesses of all sizes—from small teams to large enterprises\",\n",
              "    'You’ll also engage closely with cross-functional teams across ADP, contributing throughout the entire software development lifecycle (SDLC)—from product alignment and technical discovery to end-to-end integration and ongoing support',\n",
              "    'Success in this role requires strong collaboration, excellent communication, and deep technical expertise',\n",
              "    'You’ll lead initiatives to build services and infrastructure for our system, improve performance, scale, and the –ilities (reliability, observability, etc), and contribute to the foundation of our engineering team',\n",
              "    'You’ll help us keep our code up-to-date with best practices, and be a champion for shipping well-tested and well-organized code',\n",
              "    'You’ll be a driver for positive change to Sora’s engineering culture, processes and technology',\n",
              "    'Agile',\n",
              "    'You’ll design, develop, and test code',\n",
              "    'You’re perform code reviews for your teammates',\n",
              "    'Some days you’ll participate in stand-ups and every two weeks you’ll have sprint planning meetings',\n",
              "    'You’ll also get to interact with our customer success and sales teams to hear directly from clients and prospects',\n",
              "    'Build Products',\n",
              "    'You will use your technical expertise to review your team’s work and help your people excel in an Agile environment',\n",
              "    'When you and your team deliver a finished product, it’s as polished as you could make it',\n",
              "    'Deliver at epic scale',\n",
              "    'Act like an owner & doer',\n",
              "    'Mission-driven and committed to leading change, you will be encouraged to take on any challenge and solve complex problems']},\n",
              "  'job_onet_soc': '15113300',\n",
              "  'job_onet_job_zone': '4'},\n",
              " {'job_id': 'tPKNhZh-at3CvNuZAAAAAA==',\n",
              "  'job_title': 'Rust-based Rollup Node Developer',\n",
              "  'employer_name': 'Axiom Global',\n",
              "  'employer_logo': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT2-uxxru0rsSIB9Z-BcJXJBLnPJlDSdZ30XWH9&s=0',\n",
              "  'employer_website': 'https://axiomglobal.com',\n",
              "  'job_publisher': 'BeBee',\n",
              "  'job_employment_type': 'Full-time',\n",
              "  'job_employment_types': ['FULLTIME'],\n",
              "  'job_apply_link': 'https://us.bebee.com/job/d6747d78cdb15a7754e96898dc59872a?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': False,\n",
              "  'apply_options': [{'publisher': 'BeBee',\n",
              "    'apply_link': 'https://us.bebee.com/job/d6747d78cdb15a7754e96898dc59872a?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False}],\n",
              "  'job_description': \"We're a small but strong team that values collaboration, exceptional work ethic, and a bias towards action. Our office is located in NYC, and while we prefer candidates who can work in-person, we're open to remote applications as well.\",\n",
              "  'job_is_remote': False,\n",
              "  'job_posted_at': '2 days ago',\n",
              "  'job_posted_at_timestamp': 1743724800,\n",
              "  'job_posted_at_datetime_utc': '2025-04-04T00:00:00.000Z',\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': None,\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DtPKNhZh-at3CvNuZAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_salary': None,\n",
              "  'job_min_salary': None,\n",
              "  'job_max_salary': None,\n",
              "  'job_salary_period': None,\n",
              "  'job_highlights': {},\n",
              "  'job_onet_soc': '15113400',\n",
              "  'job_onet_job_zone': '3'},\n",
              " {'job_id': 'fLODHr08mqfCDaZPAAAAAA==',\n",
              "  'job_title': 'Senior Node.js Engineer',\n",
              "  'employer_name': 'ROSE',\n",
              "  'employer_logo': None,\n",
              "  'employer_website': None,\n",
              "  'job_publisher': 'Indeed',\n",
              "  'job_employment_type': 'Contractor',\n",
              "  'job_employment_types': ['CONTRACTOR', 'CONTRACTOR'],\n",
              "  'job_apply_link': 'https://www.indeed.com/viewjob?jk=bb8b1019dc193704&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': True,\n",
              "  'apply_options': [{'publisher': 'Indeed',\n",
              "    'apply_link': 'https://www.indeed.com/viewjob?jk=bb8b1019dc193704&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': True},\n",
              "   {'publisher': 'ROSE - JazzHR',\n",
              "    'apply_link': 'https://rosedigital.applytojob.com/apply/VvNSujYOxO/Senior-Nodejs-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'ZipRecruiter',\n",
              "    'apply_link': 'https://www.ziprecruiter.com/c/ROSE/Job/Senior-Node.js-Engineer/-in-New-York,NY?jid=9137f3dd3d62d813&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': True},\n",
              "   {'publisher': 'Built In NYC',\n",
              "    'apply_link': 'https://www.builtinnyc.com/job/senior-nodejs-engineer/299943?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Built In',\n",
              "    'apply_link': 'https://builtin.com/job/senior-nodejs-engineer/3756029?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'LinkedIn',\n",
              "    'apply_link': 'https://www.linkedin.com/jobs/view/senior-node-js-engineer-at-rose-4123290349?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Monster',\n",
              "    'apply_link': 'https://www.monster.com/job-openings/senior-node-js-engineer-new-york-ny--dcacfea7-dadd-4aac-9274-2a16e5ea88ce?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Ladders',\n",
              "    'apply_link': 'https://www.theladders.com/job/senior-node-js-engineer-rose-new-york-ny_79463458?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False}],\n",
              "  'job_description': \"This is a contract position with the ability to work remotely, however candidates must be located in the US and authorized to work in the US.\\n\\nAbout ROSE\\n\\nROSE is an award-winning digital innovation agency focused on helping leading brands leverage cutting-edge technology to innovate and delight their customers. As one of the INC 5000 fastest-growing private companies and the fastest growing Black-owned digital agency in the US we pride ourselves on the quality of our work and partnerships with our clients. We specialize in immersive technology (AR/VR) and technical partnerships leveraging web, mobile and back end development.\\n\\nWe've used WebAR to launch a new shoe line for Adidas for over 110m viewers, rebuilt the technology powering the New York Lottery, helped Patrón bring gifting into the metaverse and did our part to rewild the world with Leonardo DiCaprio and Re:wild. In doing so, the team has won multiple Webby and Shorty awards, been featured in Vogue, WWD, and Harpers Bazaar, and more importantly, had fun doing it. Our mission is to create the most innovative digital agency of our time by serving as our clients' guide and partner in digital innovation.\\n\\nAbout this position\\n\\nWe are currently looking for an experienced Back End Node.js engineer to join our Engineering team. In this role you will be responsible for maintenance and new feature development of an existing production application ecosystem. You will also be responsible for updating, and refining the processes and tools we use to create software applications for our clients. We have a mix of long-running projects with multi-year commitments that have complex development environments, shorter-run initiatives to develop functional applications quickly, and internal initiatives born out of our work that can be developed into products, collectively providing a wide variety of challenges that require thoughtful and well-designed solutions to support our engineering teams and overall company growth.\\n\\nOver time our software development team has employed various systems on our projects and have implemented solutions for source code management, automated deployments to cloud infrastructure, spinning up various pre-production and live environments, automated testing, and other processes and tooling for developing digital applications. We are looking for someone with the experience, informed opinions, and vision to take ownership of this critical area of our business and help us make projects run smoother and our clients and teams happier.\\n\\nResponsibilities\\n• Act as a senior individual contributor primarily responsible for developing and maintaining the functionality of the application ecosystem\\n• Architect new and manage existing cloud-based infrastructure for our client projects\\n• Leverage Serverless to provision and manage Infrastructure as Code\\n• Maintain existing Node.js AWS Lambda functions and the array of supporting services and utilities\\n• Refine and optimize the processes, systems, and tools used to create software applications for our client projects with the goal of creating standardized and repeatable project infrastructure.\\n• Responsible for source code management, branching and merging strategies, coordinating content and data versioning alongside code in pre-production environments, setting up and maintaining pre-production and live environments, 3rd party data & API integration, automated testing and deployments to cloud environments, and other areas that support complex modern interactive software development initiatives.\\n• Maintain and extend our CI/CD system setup in CircleCI\\n• Partner with development and QA teams to resolve issues and develop plans for testing fixes to issues in appropriate environments – coordinating code, content, data, user profiles, etc – while keeping production data and information safe.\\n• Work to identify weaknesses in systems that could lead to outages, create security breaches, develop mitigation plans, and implement solutions that lead to increased reliability, security, and overall uptime.\\n• Perform code review\\n• Proactively look for improvements over time, as new tools are released and cloud platform capabilities evolve.\\n• Contribute to software development teams for client projects and internal initiatives.\\n\\nQualifications\\n• At least three years of relevant Node.js and professional cloud-based systems engineering experience.\\n• Professional experience with Amazon Web Services (AWS) products, services and tools. Demonstrable experience including any AWS certifications encouraged and preferred.\\n• In particular a depth of experience with the following AWS services we use commonly at ROSE is strongly preferred: Lambda, API Gateway, RDS, Cognito, S3, EC2, IAM, ElasticSearch, CloudFront, CloudWatch. These are the main services we use and work with most often, but many more AWS tools and products are actively used in much of our development.\\n• Experience developing microservices and/or serverless functions with Node.js\\n• The successful candidate will be extremely well versed in the nuances of git / github, network management, utilizing and optimizing CDNs and general caching / distribution solutions and working with load balancers\\n• Experience managing deployments using command-line tools as well as CI/CD tools (CircleCI)\\n• Professional experience, ideally with enterprise-level organizations, using IaC like Serverless, AWS CDK and Terraform – design solutions and implement tools that will allow us to reduce the overall effort required for starting new initiatives and instantiating the types of projects with similar infrastructure we tend to utilize over time.\\n• Excellent communications skills to both technical and non-technical audiences, including non-technical client stakeholders.\\n• Time management skills and the ability to prioritize across initiatives based on multiple factors, project out level of effort for implementing solutions, and the ability to think ahead to possible complications or time-draining issues (including those caused by 3rd parties) and actively work to navigate around them.\\n• Exceptional problem solving and troubleshooting skills – unexpected complications or unconsidered requirements will come up, and plans will need to adapt.\\n• Solid understanding of modern security and resilience practices.\\n\\nVvNSujYOxO\",\n",
              "  'job_is_remote': False,\n",
              "  'job_posted_at': None,\n",
              "  'job_posted_at_timestamp': None,\n",
              "  'job_posted_at_datetime_utc': None,\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': None,\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DfLODHr08mqfCDaZPAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_min_salary': 30,\n",
              "  'job_max_salary': 55,\n",
              "  'job_salary_period': 'HOUR',\n",
              "  'job_highlights': {'Qualifications': ['This is a contract position with the ability to work remotely, however candidates must be located in the US and authorized to work in the US',\n",
              "    'We are looking for someone with the experience, informed opinions, and vision to take ownership of this critical area of our business and help us make projects run smoother and our clients and teams happier',\n",
              "    'At least three years of relevant Node.js and professional cloud-based systems engineering experience',\n",
              "    'Professional experience with Amazon Web Services (AWS) products, services and tools',\n",
              "    'These are the main services we use and work with most often, but many more AWS tools and products are actively used in much of our development',\n",
              "    'Experience developing microservices and/or serverless functions with Node.js',\n",
              "    'The successful candidate will be extremely well versed in the nuances of git / github, network management, utilizing and optimizing CDNs and general caching / distribution solutions and working with load balancers',\n",
              "    'Experience managing deployments using command-line tools as well as CI/CD tools (CircleCI)',\n",
              "    'Professional experience, ideally with enterprise-level organizations, using IaC like Serverless, AWS CDK and Terraform – design solutions and implement tools that will allow us to reduce the overall effort required for starting new initiatives and instantiating the types of projects with similar infrastructure we tend to utilize over time',\n",
              "    'Excellent communications skills to both technical and non-technical audiences, including non-technical client stakeholders',\n",
              "    'Time management skills and the ability to prioritize across initiatives based on multiple factors, project out level of effort for implementing solutions, and the ability to think ahead to possible complications or time-draining issues (including those caused by 3rd parties) and actively work to navigate around them',\n",
              "    'Exceptional problem solving and troubleshooting skills – unexpected complications or unconsidered requirements will come up, and plans will need to adapt',\n",
              "    'Solid understanding of modern security and resilience practices'],\n",
              "   'Responsibilities': ['In this role you will be responsible for maintenance and new feature development of an existing production application ecosystem',\n",
              "    'You will also be responsible for updating, and refining the processes and tools we use to create software applications for our clients',\n",
              "    'We have a mix of long-running projects with multi-year commitments that have complex development environments, shorter-run initiatives to develop functional applications quickly, and internal initiatives born out of our work that can be developed into products, collectively providing a wide variety of challenges that require thoughtful and well-designed solutions to support our engineering teams and overall company growth',\n",
              "    'Act as a senior individual contributor primarily responsible for developing and maintaining the functionality of the application ecosystem',\n",
              "    'Architect new and manage existing cloud-based infrastructure for our client projects',\n",
              "    'Leverage Serverless to provision and manage Infrastructure as Code',\n",
              "    'Maintain existing Node.js AWS Lambda functions and the array of supporting services and utilities',\n",
              "    'Refine and optimize the processes, systems, and tools used to create software applications for our client projects with the goal of creating standardized and repeatable project infrastructure',\n",
              "    'Responsible for source code management, branching and merging strategies, coordinating content and data versioning alongside code in pre-production environments, setting up and maintaining pre-production and live environments, 3rd party data & API integration, automated testing and deployments to cloud environments, and other areas that support complex modern interactive software development initiatives',\n",
              "    'Maintain and extend our CI/CD system setup in CircleCI',\n",
              "    'Partner with development and QA teams to resolve issues and develop plans for testing fixes to issues in appropriate environments – coordinating code, content, data, user profiles, etc – while keeping production data and information safe',\n",
              "    'Work to identify weaknesses in systems that could lead to outages, create security breaches, develop mitigation plans, and implement solutions that lead to increased reliability, security, and overall uptime',\n",
              "    'Perform code review',\n",
              "    'Proactively look for improvements over time, as new tools are released and cloud platform capabilities evolve',\n",
              "    'Contribute to software development teams for client projects and internal initiatives']},\n",
              "  'job_onet_soc': '15113400',\n",
              "  'job_onet_job_zone': '3'},\n",
              " {'job_id': 'mIRtFoH4kUD_TyYnAAAAAA==',\n",
              "  'job_title': 'Node JS Engineer Role Available',\n",
              "  'employer_name': 'TWO95 International',\n",
              "  'employer_logo': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSXTHXY-1FNHRk8BAR_TNj--jhCMfQUHZ4az2hh&s=0',\n",
              "  'employer_website': None,\n",
              "  'job_publisher': 'BeBee',\n",
              "  'job_employment_type': 'Full-time',\n",
              "  'job_employment_types': ['FULLTIME'],\n",
              "  'job_apply_link': 'https://us.bebee.com/job/e9fee24ec0b6b5668ec294bbba90afef?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': False,\n",
              "  'apply_options': [{'publisher': 'BeBee',\n",
              "    'apply_link': 'https://us.bebee.com/job/e9fee24ec0b6b5668ec294bbba90afef?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False}],\n",
              "  'job_description': 'Job Description\\n\\nAs a Senior Node JS Developer at TWO95 International, you will be working on a variety of projects that involve building scalable and efficient software applications.\\n\\nYou will be responsible for collaborating with cross-functional teams to identify project requirements and develop solutions that meet those needs.',\n",
              "  'job_is_remote': False,\n",
              "  'job_posted_at': '2 days ago',\n",
              "  'job_posted_at_timestamp': 1743724800,\n",
              "  'job_posted_at_datetime_utc': '2025-04-04T00:00:00.000Z',\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': None,\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3DmIRtFoH4kUD_TyYnAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_salary': None,\n",
              "  'job_min_salary': None,\n",
              "  'job_max_salary': None,\n",
              "  'job_salary_period': None,\n",
              "  'job_highlights': {'Responsibilities': ['As a Senior Node JS Developer at TWO95 International, you will be working on a variety of projects that involve building scalable and efficient software applications',\n",
              "    'You will be responsible for collaborating with cross-functional teams to identify project requirements and develop solutions that meet those needs']},\n",
              "  'job_onet_soc': '15113400',\n",
              "  'job_onet_job_zone': '3'},\n",
              " {'job_id': '8RjFVIz5HZukKlvDAAAAAA==',\n",
              "  'job_title': 'Backend Developer - Nodejs, Microservice',\n",
              "  'employer_name': 'CB/I Digital Inc.',\n",
              "  'employer_logo': None,\n",
              "  'employer_website': 'https://www.cbidigital.com',\n",
              "  'job_publisher': 'CB/I Digital',\n",
              "  'job_employment_type': 'Full-time',\n",
              "  'job_employment_types': ['FULLTIME'],\n",
              "  'job_apply_link': 'https://www.cbidigital.com/job/hcmc-senior-nodejs-reactjs-developer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': False,\n",
              "  'apply_options': [{'publisher': 'CB/I Digital',\n",
              "    'apply_link': 'https://www.cbidigital.com/job/hcmc-senior-nodejs-reactjs-developer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False}],\n",
              "  'job_description': 'CB/I Digital is looking for a capable Node Js back-end developer to join our team to build exciting cloud applications for our clients in the U.S. and Vietnam.',\n",
              "  'job_is_remote': False,\n",
              "  'job_posted_at': None,\n",
              "  'job_posted_at_timestamp': None,\n",
              "  'job_posted_at_datetime_utc': None,\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': None,\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D8RjFVIz5HZukKlvDAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_salary': None,\n",
              "  'job_min_salary': None,\n",
              "  'job_max_salary': None,\n",
              "  'job_salary_period': None,\n",
              "  'job_highlights': {},\n",
              "  'job_onet_soc': '15113400',\n",
              "  'job_onet_job_zone': '3'},\n",
              " {'job_id': '1-Va0cizODxYdB-kAAAAAA==',\n",
              "  'job_title': 'Full Stack w/ Nodejs and React/redux',\n",
              "  'employer_name': 'Brilliant Infotech, Inc.',\n",
              "  'employer_logo': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTkDFtOjnIMFw5S4vj80nroinUIGduTBRMI-9_-&s=0',\n",
              "  'employer_website': 'https://www.brilliantinfotech.com',\n",
              "  'job_publisher': 'ZipRecruiter',\n",
              "  'job_employment_type': 'Contractor',\n",
              "  'job_employment_types': ['CONTRACTOR', 'CONTRACTOR'],\n",
              "  'job_apply_link': 'https://www.ziprecruiter.com/c/Brilliant-Infotech,-Inc./Job/Full-Stack-w-Nodejs-and-React-redux/-in-New-York,NY?jid=4b4c65b417e648ea&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "  'job_apply_is_direct': False,\n",
              "  'apply_options': [{'publisher': 'ZipRecruiter',\n",
              "    'apply_link': 'https://www.ziprecruiter.com/c/Brilliant-Infotech,-Inc./Job/Full-Stack-w-Nodejs-and-React-redux/-in-New-York,NY?jid=4b4c65b417e648ea&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'BeBee',\n",
              "    'apply_link': 'https://us.bebee.com/job/4c08fc90fa4ac50f5ac0bbbfc5ea8aa6?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Iitjobs',\n",
              "    'apply_link': 'https://www.iitjobs.com/index.php/job/full-stack-w-nodejs-and-reactredux-nyc-ny-usa-brilliant-infotech-inc-49215?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Trabajo.org',\n",
              "    'apply_link': 'https://us.trabajo.org/job-2951-52a8210a6763accf29a7791de0f7f319?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Recruiter Jobs',\n",
              "    'apply_link': 'https://jobs.recruiter.com/jobs/15810595058-java-full-stack-developer-lead?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Lensa',\n",
              "    'apply_link': 'https://lensa.com/job-v1/diverse-lynx/new-york-ny/lead-java-full-stack-developer/da7795f278798da6f407cacaddbfc291?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False},\n",
              "   {'publisher': 'Jobilize',\n",
              "    'apply_link': 'https://www.jobilize.com/job/us-ny-long-island-full-stack-developer-lead-diverse-lynx-hiring-now?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic',\n",
              "    'is_direct': False}],\n",
              "  'job_description': \"The Expertise You Have\\n\\n6+ years of experience in designing and implementing web applications\\n\\nBachelor's degree of Computer Science or other related field.\\n\\nProfessional experience in front-end frameworks and web technologies including HTML/CSS, JavaScript or typescript, web components, Node.js or Vue.js or Angular.\\n\\nSolid knowledge with Java and/or the Open-Source stack technologies\\n\\nStrong technical background on crafting and developing enterprise digital applications with MVC design pattern, micro front-end strategy and open micro service architectures.\\n\\nProven experience with building digital restful APIs (GraphQL is a plus)\\n\\nProven experience in DevSecOps standard and tools like Jenkins or Jenkins Core, Git/GitHub.\\n\\nProven experience in container and cloud technologies, including Docker, Kubernetes and AWS, as well as secure application development.\\n\\nSolid knowledge of cloud solutions, serverless architecture, containerization strategies\\n\\nQuality-first, testable solutions using TDD and automation.\\n\\nDeep understanding and experience of version control system management using various Git workflows.\\n\\nIn-depth knowledge secure coding standards and practices\\n\\nStrong experience in leading in a reciprocal, team-based environment with a constant focus on learning, mentoring, and encouraging others.\\n\\nThe Skills You Bring\\n\\nA passion crafting outstanding experiences using your strong understanding of functional programming and front end and API design patterns.\\n\\nKnowledge of the web application landscape, architectures, trends, and emerging technologies used in crafting performant, resilient, and robust web apps.\\n\\nCreative thinker with a passion for solving big or challenging problems.\\n\\nExcellent understanding of computer science fundamentals, data structures, and algorithms to ensure alignment to software engineering methodologies.\\n\\nExcellent understanding of Test-Driven Development and Test Pyramid in support of highly resilient and stable apps with a high degree of code coverage.\\n\\nStrong understanding of modern development principles such as trunk-based development, feature toggles, and branch by abstraction to support performant and collaborative engineering teams.\\n\\nExcellent communication and influencing skills to integrate effectively into the inclusive culture.\\n\\nProven desire to learn new skills and emerging technologies/industry trends quickly.\",\n",
              "  'job_is_remote': False,\n",
              "  'job_posted_at': None,\n",
              "  'job_posted_at_timestamp': None,\n",
              "  'job_posted_at_datetime_utc': None,\n",
              "  'job_location': 'New York, NY',\n",
              "  'job_city': 'New York',\n",
              "  'job_state': 'New York',\n",
              "  'job_country': 'US',\n",
              "  'job_latitude': 40.7127753,\n",
              "  'job_longitude': -74.0059728,\n",
              "  'job_benefits': None,\n",
              "  'job_google_link': 'https://www.google.com/search?q=jobs&gl=us&hl=en&udm=8#vhid=vt%3D20/docid%3D1-Va0cizODxYdB-kAAAAAA%3D%3D&vssid=jobs-detail-viewer',\n",
              "  'job_salary': None,\n",
              "  'job_min_salary': None,\n",
              "  'job_max_salary': None,\n",
              "  'job_salary_period': None,\n",
              "  'job_highlights': {'Qualifications': ['6+ years of experience in designing and implementing web applications',\n",
              "    \"Bachelor's degree of Computer Science or other related field\",\n",
              "    'Professional experience in front-end frameworks and web technologies including HTML/CSS, JavaScript or typescript, web components, Node.js or Vue.js or Angular',\n",
              "    'Solid knowledge with Java and/or the Open-Source stack technologies',\n",
              "    'Strong technical background on crafting and developing enterprise digital applications with MVC design pattern, micro front-end strategy and open micro service architectures',\n",
              "    'Proven experience in DevSecOps standard and tools like Jenkins or Jenkins Core, Git/GitHub',\n",
              "    'Proven experience in container and cloud technologies, including Docker, Kubernetes and AWS, as well as secure application development',\n",
              "    'Solid knowledge of cloud solutions, serverless architecture, containerization strategies',\n",
              "    'Quality-first, testable solutions using TDD and automation',\n",
              "    'Deep understanding and experience of version control system management using various Git workflows',\n",
              "    'In-depth knowledge secure coding standards and practices',\n",
              "    'Strong experience in leading in a reciprocal, team-based environment with a constant focus on learning, mentoring, and encouraging others',\n",
              "    'A passion crafting outstanding experiences using your strong understanding of functional programming and front end and API design patterns',\n",
              "    'Knowledge of the web application landscape, architectures, trends, and emerging technologies used in crafting performant, resilient, and robust web apps',\n",
              "    'Creative thinker with a passion for solving big or challenging problems',\n",
              "    'Excellent understanding of computer science fundamentals, data structures, and algorithms to ensure alignment to software engineering methodologies',\n",
              "    'Excellent understanding of Test-Driven Development and Test Pyramid in support of highly resilient and stable apps with a high degree of code coverage',\n",
              "    'Strong understanding of modern development principles such as trunk-based development, feature toggles, and branch by abstraction to support performant and collaborative engineering teams',\n",
              "    'Excellent communication and influencing skills to integrate effectively into the inclusive culture',\n",
              "    'Proven desire to learn new skills and emerging technologies/industry trends quickly']},\n",
              "  'job_onet_soc': '15113400',\n",
              "  'job_onet_job_zone': '3'}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ae.utils.llm_wrapper import query_llm_mixtral\n",
        "\n",
        "cover_letter = query_llm_mixtral(prompt, temperature=0.7, max_tokens=500)\n",
        "print(\"**Generated Cover Letter:**\\n\")\n",
        "print(cover_letter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "wxj0rld1LGbR",
        "outputId": "16847bac-9d81-495a-bd97-6425d32c4ac5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "RapidAPI LLM request failed: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/utils/llm_wrapper.py\u001b[0m in \u001b[0;36mquery_llm_mixtral\u001b[0;34m(prompt, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-49c130e9be0e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery_llm_mixtral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcover_letter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_llm_mixtral\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"**Generated Cover Letter:**\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_letter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Agent-E-master_xxx/ae/utils/llm_wrapper.py\u001b[0m in \u001b[0;36mquery_llm_mixtral\u001b[0;34m(prompt, temperature, max_tokens)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RapidAPI LLM request failed: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Parse response (handle JSON or plain text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: RapidAPI LLM request failed: 403 Client Error: Forbidden for url: https://llm-api1.p.rapidapi.com/v0/llmchat"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/mixtral-8x7b\"  # ✅ Correct"
      ],
      "metadata": {
        "id": "ijV9TqGSLenX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Overwrite pyproject.toml with setuptools and wheel (instead of uv.build_api)\n",
        "with open(\"/content/Agent-E-master_xxx/pyproject.toml\", \"w\") as f:\n",
        "    f.write(\"\"\"[build-system]\n",
        "requires = [\"setuptools\", \"wheel\"]\n",
        "build-backend = \"setuptools.build_meta\"\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "lrhP0d6IL4dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "url = \"https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/mixtral-8x7b\"\n",
        "headers = {\n",
        "    \"content-type\": \"application/json\",\n",
        "    \"X-RapidAPI-Key\": \"be5738a9e9msh08bfcd8fad98672p136d4bjsn7df8eb80c816\",  # Replace with real key\n",
        "    \"X-RapidAPI-Host\": \"llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com\"\n",
        "}\n",
        "payload = {\n",
        "    \"prompt\": \"Write a one-line cover letter for a software engineer job\",\n",
        "    \"max_tokens\": 100,\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "\n",
        "resp = requests.post(url, json=payload, headers=headers)\n",
        "print(resp.status_code)\n",
        "print(resp.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrXgBgASO0OY",
        "outputId": "504d17ea-bbc6-469e-86e8-06ffdacc5a2e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404\n",
            "{\"message\":\"Endpoint '\\/mixtral-8x7b' does not exist\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/nmixtral"
      ],
      "metadata": {
        "id": "pl6ynCQ4PDRd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "# 🔁 Replace with your actual RapidAPI key\n",
        "os.environ[\"AUTOGEN_MODEL_API_KEY\"] = \"be5738a9e9msh08bfcd8fad98672p136d4bjsn7df8eb80c816\"\n",
        "\n",
        "url = \"https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/nmixtral\"\n",
        "\n",
        "headers = {\n",
        "    \"content-type\": \"application/json\",\n",
        "    \"X-RapidAPI-Key\": os.environ[\"AUTOGEN_MODEL_API_KEY\"],\n",
        "    \"X-RapidAPI-Host\": \"llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}],\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 100,\n",
        "    \"web_access\": False,\n",
        "    \"consider_chat_history\": False,\n",
        "    \"system_prompt\": \"\",\n",
        "    \"conversation_id\": \"\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    resp = requests.post(url, json=payload, headers=headers, timeout=60)\n",
        "    print(\"✅ Response:\", resp.json())\n",
        "except Exception as e:\n",
        "    print(\"❌ Error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgH2uL_KP_n9",
        "outputId": "882ef9b2-2ed7-4892-f8d3-89d2ff674f31"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Response: {'result': 'Why did the scarecrow win an award? \\n\\nBecause he was outstanding in his field!', 'conversation_id': 'ZeO2XpE174396271510YHt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "Ol-wVrr8Ssps"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seen_ids = set()\n",
        "while True:\n",
        "    new_jobs = []\n",
        "    results = requests.get(api_url, headers=api_headers, params=query_params).json().get(\"data\", [])\n",
        "    for job in results:\n",
        "        if job['job_id'] not in seen_ids:\n",
        "            new_jobs.append(job)\n",
        "            seen_ids.add(job['job_id'])\n",
        "    if new_jobs:\n",
        "        print(f\"🎉 Found {len(new_jobs)} new job postings!\")\n",
        "        for job in new_jobs:\n",
        "            print(f\"New job: {job['job_title']} at {job['employer_name']}\")\n",
        "            # Here you could generate a cover letter or take other actions\n",
        "    time.sleep(3600)  # wait an hour (3600 seconds) before checking again\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "d7yX5eh8RzCd",
        "outputId": "a7e32017-2fae-460c-a178-67c155fef3d6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a5648fa64839>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"New job: {job['job_title']} at {job['employer_name']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Here you could generate a cover letter or take other actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait an hour (3600 seconds) before checking again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"AUTOGEN_MODEL_API_KEY\"] = \"be5738a9e9msh08bfcd8fad98672p136d4bjsn7df8eb80c816\"  # <- 🔁 Replace this only\n",
        "os.environ[\"AUTOGEN_MODEL_BASE_URL\"] = \"https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/nmixtral\"\n",
        "os.environ[\"AUTOGEN_MODEL_NAME\"] = \"mixtral-8x7b-instruct\""
      ],
      "metadata": {
        "id": "DsZkHWC6SdkM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def query_llm_mixtral(prompt, temperature=0.7, max_tokens=500):\n",
        "    url = os.environ[\"AUTOGEN_MODEL_BASE_URL\"]\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"X-RapidAPI-Key\": os.environ[\"AUTOGEN_MODEL_API_KEY\"],\n",
        "        \"X-RapidAPI-Host\": \"llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"prompt\": prompt,\n",
        "        \"temperature\": temperature,\n",
        "        \"max_tokens\": max_tokens\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, json=payload, headers=headers, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        # Auto-adapt to structure\n",
        "        if \"message\" in data:\n",
        "            return data[\"message\"]\n",
        "        elif \"content\" in data:\n",
        "            return data[\"content\"]\n",
        "        elif \"choices\" in data:\n",
        "            return data[\"choices\"][0].get(\"message\", {}).get(\"content\", \"\")\n",
        "        return str(data)\n",
        "    except Exception as e:\n",
        "        return f\"ERROR: {e}\"\n"
      ],
      "metadata": {
        "id": "iFeUZLFhUWsk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_llm_mixtral(\"Summarize the benefits of drinking water.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4Nobm2hUnHI",
        "outputId": "2de8cd9e-ab33-4d81-ddf1-d564d94efa25"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'status': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JgGPaNr_VMul",
        "outputId": "910409b0-1411-43d6-d196-d13905146008"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/mixtral-8x7b'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seen_ids = set()\n",
        "while True:\n",
        "    new_jobs = []\n",
        "    results = requests.get(api_url, headers=api_headers, params=query_params).json().get(\"data\", [])\n",
        "    for job in results:\n",
        "        if job['job_id'] not in seen_ids:\n",
        "            new_jobs.append(job)\n",
        "            seen_ids.add(job['job_id'])\n",
        "    if new_jobs:\n",
        "        print(f\"🎉 Found {len(new_jobs)} new job postings!\")\n",
        "        for job in new_jobs:\n",
        "            print(f\"New job: {job['job_title']} at {job['employer_name']}\")\n",
        "            # Here you could generate a cover letter or take other actions\n",
        "    time.sleep(3600)  # wait an hour (3600 seconds) before checking again\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "m41UiRwRUrp9",
        "outputId": "7be96652-47d6-4444-edde-6123bf90e9ed"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-a5648fa64839>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"New job: {job['job_title']} at {job['employer_name']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Here you could generate a cover letter or take other actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait an hour (3600 seconds) before checking again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def autogen_compatible_mixtral_completion(messages, **kwargs):\n",
        "    from ae.utils.llm_mixtral_wrapper import query_llm_mixtral\n",
        "    user_prompt = messages[-1][\"content\"]\n",
        "    return {\"role\": \"assistant\", \"content\": query_llm_mixtral(user_prompt)}"
      ],
      "metadata": {
        "id": "IFnHgljNVTKn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_config = {\n",
        "    \"config_list\": [{\"model\": \"mixtral-rapidapi\"}],\n",
        "    \"completion_func\": autogen_compatible_mixtral_completion\n",
        "}"
      ],
      "metadata": {
        "id": "aezRmwh5WOxk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AssistantAgent(name=\"planner\", llm_config=llm_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "6GG360xBWTMp",
        "outputId": "90474efc-4a49-4752-f173-89fad8cbf635"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AssistantAgent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-fa33249e119b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAssistantAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"planner\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'AssistantAgent' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"AUTOGEN_MODEL_API_KEY\"] = \"be5738a9e9msh08bfcd8fad98672p136d4bjsn7df8eb80c816\"\n",
        "os.environ[\"AUTOGEN_MODEL_NAME\"] = \"mixtral-8x7b-instruct\""
      ],
      "metadata": {
        "id": "6CoPIpBYWWvK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "planner_agent_model_config = {\n",
        "    \"config_list\": [{\"model\": \"mixtral-rapidapi\"}],\n",
        "    \"completion_func\": autogen_compatible_mixtral_completion\n",
        "}"
      ],
      "metadata": {
        "id": "soAGNqQOWoVT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PlannerAgent(planner_agent_model_config, llm_config_params, prompt, user_proxy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "GVNop2QOXCNQ",
        "outputId": "4248e016-aff8-4442-d1bf-7662b4c3cdde"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PlannerAgent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-da742538793c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPlannerAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplanner_agent_model_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_config_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_proxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'PlannerAgent' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyautogen==0.7.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM63b-bHXFX_",
        "outputId": "3ef3c0e0-f4e9-4c5a-b222-b857fe83f410"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyautogen==0.7.0 in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: asyncer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (0.0.8)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (5.6.3)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (7.1.0)\n",
            "Requirement already satisfied: fast-depends<3,>=2.4.12 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (2.4.12)\n",
            "Requirement already satisfied: flaml in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (2.3.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (1.24.3)\n",
            "Requirement already satisfied: openai>=1.58 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (1.59.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (24.2)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (2.6.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (1.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (2.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (0.8.0)\n",
            "Requirement already satisfied: websockets<15,>=14 in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.7.0) (14.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from asyncer==0.0.8->pyautogen==0.7.0) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.0) (0.26.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.0) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.0) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.58->pyautogen==0.7.0) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.7.0) (2.16.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen==0.7.0) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker->pyautogen==0.7.0) (2.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->pyautogen==0.7.0) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.4.0->asyncer==0.0.8->pyautogen==0.7.0) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.0) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.58->pyautogen==0.7.0) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->docker->pyautogen==0.7.0) (3.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import AssistantAgent, UserProxyAgent\n",
        "from autogen.agentchat.contrib.capability_agent import PlannerAgent\n",
        "\n",
        "# Simple assistant config\n",
        "llm_config = {\n",
        "    \"config_list\": [\n",
        "        {\n",
        "            \"model\": \"mixtral-8x7b-instruct\",  # replace with your model if needed\n",
        "            \"api_key\": \"be5738a9e9msh08bfcd8fad98672p136d4bjsn7df8eb80c816\",\n",
        "        }\n",
        "    ],\n",
        "    \"cache_seed\": 42,\n",
        "}\n",
        "\n",
        "# User proxy\n",
        "user_proxy = UserProxyAgent(name=\"user\", human_input_mode=\"NEVER\")\n",
        "\n",
        "# Assistant\n",
        "assistant = AssistantAgent(name=\"assistant\", llm_config=llm_config)\n",
        "\n",
        "# Planner\n",
        "planner = PlannerAgent(llm_config=llm_config, assistant=assistant)\n",
        "\n",
        "# Run a simple chat (optional)\n",
        "user_proxy.initiate_chat(planner, message=\"Give me 3 ideas for a startup.\")\n"
      ],
      "metadata": {
        "id": "4OP0GoH4YLEM",
        "outputId": "54a9be6d-a1bb-435f-b8c9-6f3e3d90b142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'autogen.agentchat.contrib.capability_agent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-29504499fc05>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAssistantAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserProxyAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magentchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapability_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlannerAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Simple assistant config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m llm_config = {\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autogen.agentchat.contrib.capability_agent'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import AssistantAgent, UserProxyAgent"
      ],
      "metadata": {
        "id": "rX_hjZD2YpUf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y pyautogen"
      ],
      "metadata": {
        "id": "k6No1CU6ZAjp",
        "outputId": "a9a202d4-5754-47d6-c6a6-1ae953529371",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pyautogen 0.7.0\n",
            "Uninstalling pyautogen-0.7.0:\n",
            "  Successfully uninstalled pyautogen-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/microsoft/autogen.git@main"
      ],
      "metadata": {
        "id": "l1RaT2MwZNjp",
        "outputId": "a97609ed-8027-47b7-82e4-b51a111b3191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/microsoft/autogen.git@main\n",
            "  Cloning https://github.com/microsoft/autogen.git (to revision main) to /tmp/pip-req-build-75032lnt\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/microsoft/autogen.git /tmp/pip-req-build-75032lnt\n",
            "  Resolved https://github.com/microsoft/autogen.git to commit b6705115d11e18925dd3f0b068dbd5681d6b8159\n",
            "\u001b[31mERROR: git+https://github.com/microsoft/autogen.git@main does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y autogen pyautogen\n"
      ],
      "metadata": {
        "id": "5FbhYwe5ZQHE",
        "outputId": "286b7d56-19eb-4169-80e6-73535756aa10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: autogen 0.7.0\n",
            "Uninstalling autogen-0.7.0:\n",
            "  Successfully uninstalled autogen-0.7.0\n",
            "\u001b[33mWARNING: Skipping pyautogen as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyautogen==0.1.5\n"
      ],
      "metadata": {
        "id": "tyRDDxhJaEKu",
        "outputId": "ff24e48c-7770-43d4-e199-6bf7d9bce56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen==0.1.5\n",
            "  Using cached pyautogen-0.1.5-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.1.5) (5.6.3)\n",
            "Requirement already satisfied: flaml in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.1.5) (2.3.3)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.1.5) (1.59.7)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from pyautogen==0.1.5) (2.5.0)\n",
            "Requirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.11/dist-packages (from flaml->pyautogen==0.1.5) (1.24.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (0.26.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (2.6.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai->pyautogen==0.1.5) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai->pyautogen==0.1.5) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->pyautogen==0.1.5) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->pyautogen==0.1.5) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->pyautogen==0.1.5) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->pyautogen==0.1.5) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai->pyautogen==0.1.5) (2.16.3)\n",
            "Using cached pyautogen-0.1.5-py3-none-any.whl (68 kB)\n",
            "Installing collected packages: pyautogen\n",
            "Successfully installed pyautogen-0.1.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "autogen"
                ]
              },
              "id": "8da7fb9fe00e4fbaa7ddc71b2aeabc26"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import AssistantAgent, UserProxyAgent\n",
        "from autogen.agentchat.contrib.capability_agent import PlannerAgent\n"
      ],
      "metadata": {
        "id": "8FevrtnCaG8o",
        "outputId": "164dc7bf-2c5a-46ac-fab9-47bf59a28051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'autogen.agentchat.contrib.capability_agent'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-b32d4a2ddf22>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAssistantAgent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserProxyAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magentchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapability_agent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlannerAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autogen.agentchat.contrib.capability_agent'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com/nmixtral\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"X-RapidAPI-Key\": \"be5738a9e9msh08bfcd8fad98672p136d4bjsn7df8eb80c816\",  # <- Replace with your actual key\n",
        "    \"X-RapidAPI-Host\": \"llama-ai-mixtral-cohere-gpt-api.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "payload = {\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What's a fun fact about black holes?\"}],\n",
        "    \"web_access\": False,\n",
        "    \"consider_chat_history\": False,\n",
        "    \"system_prompt\": \"\",\n",
        "    \"conversation_id\": \"\",\n",
        "    \"temperature\": 0.7,\n",
        "    \"max_tokens\": 100\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=payload)\n",
        "print(\"Status Code:\", response.status_code)\n",
        "print(\"Response:\", response.text)\n"
      ],
      "metadata": {
        "id": "r-8Eo-XaaL-2",
        "outputId": "3ec62de6-83bf-41ea-de43-5832eb3d29c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Response: {\"result\":\"A fun fact about black holes is that they can \\\"sing\\\"! When two black holes merge, they produce gravitational waves—ripples in spacetime that can be detected by observatories like LIGO. The frequencies of these waves can be translated into sound waves, allowing scientists to \\\"hear\\\" the merger. The resulting sound is often described as a chirp, which is a unique and fascinating way to experience the cosmic events happening in the universe!\",\"conversation_id\":\"KwkIOSv174396508984Fbu\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "70TVwnSia25E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}